{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf584ce8-8849-4a53-8ce9-2de8f9dd752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify GPU to use\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52b07238-f972-45df-86ce-a11cc11d72e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 5361\n",
      "Validation set size: 1341\n",
      "Test set size: 1676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smarton/anaconda3/envs/GradientBasedTreeLearning/lib/python3.11/site-packages/openml/datasets/functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import openml\n",
    "import category_encoders as ce\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "# Load SpeedDating dataset\n",
    "dataset = openml.datasets.get_dataset(40536)\n",
    "X, y, categorical_indicator, attribute_names = dataset.get_data(target=dataset.default_target_attribute)\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Validation set size:\", len(X_valid))\n",
    "print(\"Test set size:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a22e5c9-16a8-44ab-b8fa-19344b93dd22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_null</th>\n",
       "      <th>wave</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>d_age</th>\n",
       "      <th>d_d_age</th>\n",
       "      <th>race</th>\n",
       "      <th>race_o</th>\n",
       "      <th>samerace</th>\n",
       "      <th>...</th>\n",
       "      <th>expected_num_interested_in_me</th>\n",
       "      <th>expected_num_matches</th>\n",
       "      <th>d_expected_happy_with_sd_people</th>\n",
       "      <th>d_expected_num_interested_in_me</th>\n",
       "      <th>d_expected_num_matches</th>\n",
       "      <th>like</th>\n",
       "      <th>guess_prob_liked</th>\n",
       "      <th>d_like</th>\n",
       "      <th>d_guess_prob_liked</th>\n",
       "      <th>met</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[0-4]</td>\n",
       "      <td>[10-20]</td>\n",
       "      <td>[3-5]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[0-5]</td>\n",
       "      <td>[7-10]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>female</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Black/African American</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[5-6]</td>\n",
       "      <td>[0-3]</td>\n",
       "      <td>[3-5]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[6-8]</td>\n",
       "      <td>[7-10]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>Black/African American</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[7-10]</td>\n",
       "      <td>[0-3]</td>\n",
       "      <td>[0-2]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0-5]</td>\n",
       "      <td>[0-4]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5972</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4</td>\n",
       "      <td>[4-6]</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>European/Caucasian-American</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0-4]</td>\n",
       "      <td>[0-3]</td>\n",
       "      <td>[0-2]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[0-5]</td>\n",
       "      <td>[5-6]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5443</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0-1]</td>\n",
       "      <td>Asian/Pacific Islander/Asian-American</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[7-10]</td>\n",
       "      <td>[0-3]</td>\n",
       "      <td>[3-5]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[0-5]</td>\n",
       "      <td>[0-4]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     has_null  wave  gender   age  age_o  d_age d_d_age  \\\n",
       "813         0     3  female  23.0   21.0      2   [2-3]   \n",
       "1677        1     5  female  20.0   18.0      2   [2-3]   \n",
       "2915        1     9  female  28.0   27.0      1   [0-1]   \n",
       "5972        1    15  female  28.0   24.0      4   [4-6]   \n",
       "5443        1    14    male  23.0   24.0      1   [0-1]   \n",
       "\n",
       "                                       race  \\\n",
       "813             European/Caucasian-American   \n",
       "1677                 Black/African American   \n",
       "2915                 Black/African American   \n",
       "5972            European/Caucasian-American   \n",
       "5443  Asian/Pacific Islander/Asian-American   \n",
       "\n",
       "                                     race_o samerace  ...  \\\n",
       "813             European/Caucasian-American        1  ...   \n",
       "1677  Asian/Pacific Islander/Asian-American        0  ...   \n",
       "2915  Asian/Pacific Islander/Asian-American        0  ...   \n",
       "5972            European/Caucasian-American        1  ...   \n",
       "5443                                  Other        0  ...   \n",
       "\n",
       "      expected_num_interested_in_me  expected_num_matches  \\\n",
       "813                            15.0                   3.0   \n",
       "1677                            NaN                   3.0   \n",
       "2915                            NaN                   0.0   \n",
       "5972                            NaN                   1.0   \n",
       "5443                            NaN                   4.0   \n",
       "\n",
       "     d_expected_happy_with_sd_people d_expected_num_interested_in_me  \\\n",
       "813                            [0-4]                         [10-20]   \n",
       "1677                           [5-6]                           [0-3]   \n",
       "2915                          [7-10]                           [0-3]   \n",
       "5972                           [0-4]                           [0-3]   \n",
       "5443                          [7-10]                           [0-3]   \n",
       "\n",
       "     d_expected_num_matches  like  guess_prob_liked  d_like  \\\n",
       "813                   [3-5]   5.0              10.0   [0-5]   \n",
       "1677                  [3-5]   7.0               7.0   [6-8]   \n",
       "2915                  [0-2]   NaN               NaN   [0-5]   \n",
       "5972                  [0-2]   3.0               5.0   [0-5]   \n",
       "5443                  [3-5]   5.0               4.0   [0-5]   \n",
       "\n",
       "      d_guess_prob_liked  met  \n",
       "813               [7-10]  0.0  \n",
       "1677              [7-10]  0.0  \n",
       "2915               [0-4]  NaN  \n",
       "5972               [5-6]  0.0  \n",
       "5443               [0-4]  0.0  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c846edc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = X_train.copy()\n",
    "X_valid_raw = X_valid.copy()\n",
    "X_test_raw = X_test.copy()\n",
    "\n",
    "low_cardinality_indices = []\n",
    "high_cardinality_indices = []\n",
    "\n",
    "categorical_feature_indices = []\n",
    "for column_index in range(X_train.shape[1]):\n",
    "    if categorical_indicator[column_index]:\n",
    "        categorical_feature_indices.append(column_index)\n",
    "        if len(X_train.iloc[:,column_index].unique()) < 10:\n",
    "            low_cardinality_indices.append(X_train.columns[column_index])\n",
    "        else:\n",
    "            high_cardinality_indices.append(X_train.columns[column_index])\n",
    "\n",
    "y_train = y_train.values.codes.astype(np.float64)\n",
    "y_valid = y_valid.values.codes.astype(np.float64)\n",
    "y_test = y_test.values.codes.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "830c0041",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.OrdinalEncoder(cols=X_train.columns[categorical_feature_indices])\n",
    "encoder.fit(X_train)\n",
    "X_train = encoder.transform(X_train).astype(np.float64)\n",
    "X_valid = encoder.transform(X_valid).astype(np.float64)\n",
    "X_test = encoder.transform(X_test).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf0a93c2-e9a4-4fa5-a7f6-44689dd07d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 15:18:16.328503: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-02 15:18:18.344896: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/smarton/anaconda3/envs/GradientBasedTreeLearning/lib/python3.11/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "2023-11-02 15:18:21.562338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46332 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:a1:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 15:18:26.662030: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x22a729d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-02 15:18:26.662089: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2023-11-02 15:18:26.678964: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-02 15:18:27.862780: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8801\n",
      "2023-11-02 15:18:29.117989: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 14s 73ms/step - loss: 0.6070 - val_loss: 0.5224\n",
      "Epoch 2/1000\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 0.4613 - val_loss: 0.4119\n",
      "Epoch 3/1000\n",
      "84/84 [==============================] - 3s 39ms/step - loss: 0.3799 - val_loss: 0.3676\n",
      "Epoch 4/1000\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 0.3457 - val_loss: 0.3522\n",
      "Epoch 5/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.3321 - val_loss: 0.3478\n",
      "Epoch 6/1000\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 0.3243 - val_loss: 0.3464\n",
      "Epoch 7/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.3194 - val_loss: 0.3452\n",
      "Epoch 8/1000\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 0.3153 - val_loss: 0.3432\n",
      "Epoch 9/1000\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 0.3117 - val_loss: 0.3419\n",
      "Epoch 10/1000\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 0.3086 - val_loss: 0.3411\n",
      "Epoch 11/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.3054 - val_loss: 0.3400\n",
      "Epoch 12/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.3019 - val_loss: 0.3380\n",
      "Epoch 13/1000\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 0.2989 - val_loss: 0.3375\n",
      "Epoch 14/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.2958 - val_loss: 0.3362\n",
      "Epoch 15/1000\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 0.2934 - val_loss: 0.3358\n",
      "Epoch 16/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.2905 - val_loss: 0.3358\n",
      "Epoch 17/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.2870 - val_loss: 0.3318\n",
      "Epoch 18/1000\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 0.2846 - val_loss: 0.3331\n",
      "Epoch 19/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.2821 - val_loss: 0.3297\n",
      "Epoch 20/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.2791 - val_loss: 0.3307\n",
      "Epoch 21/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.2756 - val_loss: 0.3311\n",
      "Epoch 22/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.2730 - val_loss: 0.3309\n",
      "Epoch 23/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.2698 - val_loss: 0.3306\n",
      "Epoch 24/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.2669 - val_loss: 0.3299\n",
      "Epoch 25/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.2642 - val_loss: 0.3297\n",
      "Epoch 26/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.2610 - val_loss: 0.3285\n",
      "Epoch 27/1000\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 0.2575 - val_loss: 0.3282\n",
      "Epoch 28/1000\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 0.2545 - val_loss: 0.3289\n",
      "Epoch 29/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.2511 - val_loss: 0.3290\n",
      "Epoch 30/1000\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 0.2479 - val_loss: 0.3283\n",
      "Epoch 31/1000\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 0.2438 - val_loss: 0.3251\n",
      "Epoch 32/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.2399 - val_loss: 0.3273\n",
      "Epoch 33/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.2360 - val_loss: 0.3263\n",
      "Epoch 34/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.2331 - val_loss: 0.3302\n",
      "Epoch 35/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.2291 - val_loss: 0.3276\n",
      "Epoch 36/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.2261 - val_loss: 0.3279\n",
      "Epoch 37/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.2221 - val_loss: 0.3293\n",
      "Epoch 38/1000\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 0.2185 - val_loss: 0.3287\n",
      "Epoch 39/1000\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 0.2146 - val_loss: 0.3283\n",
      "Epoch 40/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.2100 - val_loss: 0.3298\n",
      "Epoch 41/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.2058 - val_loss: 0.3270\n",
      "Epoch 42/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.2029 - val_loss: 0.3311\n",
      "Epoch 43/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.1993 - val_loss: 0.3284\n",
      "Epoch 44/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.1954 - val_loss: 0.3289\n",
      "Epoch 45/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.1905 - val_loss: 0.3293\n",
      "Epoch 46/1000\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 0.1865 - val_loss: 0.3327\n",
      "Epoch 47/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.1821 - val_loss: 0.3354\n",
      "Epoch 48/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.1789 - val_loss: 0.3354\n",
      "Epoch 49/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.1737 - val_loss: 0.3401\n",
      "Epoch 50/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.1709 - val_loss: 0.3377\n",
      "Epoch 51/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.1663 - val_loss: 0.3428\n",
      "Epoch 52/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.1626 - val_loss: 0.3380\n",
      "Epoch 53/1000\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 0.1602 - val_loss: 0.3427\n",
      "Epoch 54/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.1572 - val_loss: 0.3460\n",
      "Epoch 55/1000\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 0.1526 - val_loss: 0.3456\n",
      "Epoch 56/1000\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.1495 - val_loss: 0.3505\n"
     ]
    }
   ],
   "source": [
    "from GRANDE import GRANDE\n",
    "\n",
    "params = {\n",
    "        'depth': 5,\n",
    "        'n_estimators': 2048,\n",
    "\n",
    "        'learning_rate_weights': 0.005,\n",
    "        'learning_rate_index': 0.01,\n",
    "        'learning_rate_values': 0.01,\n",
    "        'learning_rate_leaf': 0.01,\n",
    "\n",
    "        'optimizer': 'SWA',\n",
    "        'cosine_decay_steps': 0,\n",
    "\n",
    "        'initializer': 'RandomNormal',\n",
    "\n",
    "        'loss': 'crossentropy',\n",
    "        'focal_loss': False,\n",
    "        'temperature': 0.0,\n",
    "\n",
    "        'from_logits': True,\n",
    "        'apply_class_balancing': True,\n",
    "\n",
    "        'dropout': 0.0,\n",
    "\n",
    "        'selected_variables': 0.8,\n",
    "        'data_subset_fraction': 1.0,\n",
    "}\n",
    "\n",
    "args = {\n",
    "    'epochs': 1_000,\n",
    "    'early_stopping_epochs': 25,\n",
    "    'batch_size': 64,\n",
    "\n",
    "    'cat_idx': categorical_feature_indices,\n",
    "    'objective': 'binary',\n",
    "    \n",
    "    'metrics': ['F1'], # F1, Accuracy, R2\n",
    "    'random_seed': 42,\n",
    "    'verbose': 1,       \n",
    "}\n",
    "\n",
    "model_grande = GRANDE(params=params, args=args)\n",
    "\n",
    "model_grande.fit(X_train=X_train,\n",
    "          y_train=y_train,\n",
    "          X_val=X_valid,\n",
    "          y_val=y_valid)\n",
    "\n",
    "preds_grande = model_grande.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b251df9d-67f0-4dd1-a0cc-379621e33fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sample_weights(y_data):\n",
    "    class_weights = sklearn.utils.class_weight.compute_class_weight(class_weight = 'balanced', classes = np.unique(y_data), y = y_data)\n",
    "    #class_weights = class_weights/sum(class_weights)#    \n",
    "    sample_weights = sklearn.utils.class_weight.compute_sample_weight(class_weight = 'balanced', y =y_data)\n",
    "    #sample_weights = sample_weights/sum(class_weights)\n",
    "    return sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5d5f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "median = X_train.median(axis=0)\n",
    "X_train= X_train.fillna(median)\n",
    "X_vali = X_valid.fillna(median)\n",
    "X_test = X_test.fillna(median)\n",
    "\n",
    "encoder = ce.LeaveOneOutEncoder(cols=high_cardinality_indices)\n",
    "encoder.fit(X_train, y_train)\n",
    "X_train = encoder.transform(X_train)\n",
    "X_valid = encoder.transform(X_valid)\n",
    "X_test = encoder.transform(X_test)\n",
    "\n",
    "encoder = ce.OneHotEncoder(cols=low_cardinality_indices)\n",
    "encoder.fit(X_train)\n",
    "X_train = encoder.transform(X_train)\n",
    "X_valid = encoder.transform(X_valid)\n",
    "X_test = encoder.transform(X_test)\n",
    "\n",
    "median = X_train.median(axis=0)\n",
    "X_train = X_train.fillna(median)\n",
    "X_valid = X_valid.fillna(median)\n",
    "X_test = X_test.fillna(median)\n",
    "\n",
    "quantile_noise = 1e-4\n",
    "quantile_train = np.copy(X_train.values).astype(np.float64)\n",
    "np.random.seed(42)\n",
    "stds = np.std(quantile_train, axis=0, keepdims=True)\n",
    "noise_std = quantile_noise / np.maximum(stds, quantile_noise)\n",
    "quantile_train += noise_std * np.random.randn(*quantile_train.shape)       \n",
    "\n",
    "scaler = sklearn.preprocessing.QuantileTransformer(output_distribution='normal')\n",
    "scaler.fit(quantile_train)\n",
    "\n",
    "X_train = scaler.transform(X_train.values.astype(np.float64))\n",
    "X_valid = scaler.transform(X_valid.values.astype(np.float64))\n",
    "X_test = scaler.transform(X_test.values.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "361f7d9f-7e58-4bc1-8855-153b9e972742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.61617\n",
      "[1]\tvalidation_0-logloss:0.58583\n",
      "[2]\tvalidation_0-logloss:0.57171\n",
      "[3]\tvalidation_0-logloss:0.56602\n",
      "[4]\tvalidation_0-logloss:0.57168\n",
      "[5]\tvalidation_0-logloss:0.56915\n",
      "[6]\tvalidation_0-logloss:0.57535\n",
      "[7]\tvalidation_0-logloss:0.58421\n",
      "[8]\tvalidation_0-logloss:0.59058\n",
      "[9]\tvalidation_0-logloss:0.59599\n",
      "[10]\tvalidation_0-logloss:0.60741\n",
      "[11]\tvalidation_0-logloss:0.62176\n",
      "[12]\tvalidation_0-logloss:0.62515\n",
      "[13]\tvalidation_0-logloss:0.63687\n",
      "[14]\tvalidation_0-logloss:0.64298\n",
      "[15]\tvalidation_0-logloss:0.64503\n",
      "[16]\tvalidation_0-logloss:0.64726\n",
      "[17]\tvalidation_0-logloss:0.65866\n",
      "[18]\tvalidation_0-logloss:0.66732\n",
      "[19]\tvalidation_0-logloss:0.66513\n",
      "[20]\tvalidation_0-logloss:0.67006\n",
      "[21]\tvalidation_0-logloss:0.67947\n",
      "[22]\tvalidation_0-logloss:0.68068\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model_xgb = XGBClassifier(n_estimators=1000, early_stopping_rounds=20)\n",
    "model_xgb.fit(X_train, \n",
    "                y_train, \n",
    "                sample_weight=calculate_sample_weights(y_train), \n",
    "                eval_set=[(X_valid, y_valid)], \n",
    "                sample_weight_eval_set=[calculate_sample_weights(y_valid)]\n",
    "             )\n",
    "\n",
    "preds_xgb = model_xgb.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25016783",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.OrdinalEncoder(cols=X_train_raw.columns[categorical_feature_indices])\n",
    "encoder.fit(X_train_raw)\n",
    "X_train_raw = encoder.transform(X_train_raw)\n",
    "X_valid_raw = encoder.transform(X_valid_raw)\n",
    "X_test_raw = encoder.transform(X_test_raw)\n",
    "\n",
    "median = X_train_raw.median(axis=0)\n",
    "X_train_raw = X_train_raw.fillna(median)\n",
    "X_valid_raw = X_valid_raw.fillna(median)\n",
    "X_test_raw = X_test_raw.fillna(median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b23c67e-cdde-40c2-842a-61383e1a62d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.047977\n",
      "0:\tlearn: 0.6738749\ttest: 0.6755616\tbest: 0.6755616 (0)\ttotal: 180ms\tremaining: 2m 59s\n",
      "1:\tlearn: 0.6590376\ttest: 0.6621054\tbest: 0.6621054 (1)\ttotal: 250ms\tremaining: 2m 4s\n",
      "2:\tlearn: 0.6476492\ttest: 0.6530350\tbest: 0.6530350 (2)\ttotal: 311ms\tremaining: 1m 43s\n",
      "3:\tlearn: 0.6334984\ttest: 0.6409063\tbest: 0.6409063 (3)\ttotal: 420ms\tremaining: 1m 44s\n",
      "4:\tlearn: 0.6211706\ttest: 0.6295918\tbest: 0.6295918 (4)\ttotal: 516ms\tremaining: 1m 42s\n",
      "5:\tlearn: 0.6089204\ttest: 0.6190270\tbest: 0.6190270 (5)\ttotal: 611ms\tremaining: 1m 41s\n",
      "6:\tlearn: 0.5978930\ttest: 0.6102024\tbest: 0.6102024 (6)\ttotal: 707ms\tremaining: 1m 40s\n",
      "7:\tlearn: 0.5884188\ttest: 0.6025458\tbest: 0.6025458 (7)\ttotal: 798ms\tremaining: 1m 38s\n",
      "8:\tlearn: 0.5827542\ttest: 0.5988541\tbest: 0.5988541 (8)\ttotal: 836ms\tremaining: 1m 32s\n",
      "9:\tlearn: 0.5709456\ttest: 0.5900052\tbest: 0.5900052 (9)\ttotal: 928ms\tremaining: 1m 31s\n",
      "10:\tlearn: 0.5629534\ttest: 0.5835565\tbest: 0.5835565 (10)\ttotal: 1.02s\tremaining: 1m 32s\n",
      "11:\tlearn: 0.5573729\ttest: 0.5791025\tbest: 0.5791025 (11)\ttotal: 1.08s\tremaining: 1m 28s\n",
      "12:\tlearn: 0.5515122\ttest: 0.5739364\tbest: 0.5739364 (12)\ttotal: 1.15s\tremaining: 1m 27s\n",
      "13:\tlearn: 0.5440245\ttest: 0.5679286\tbest: 0.5679286 (13)\ttotal: 1.25s\tremaining: 1m 27s\n",
      "14:\tlearn: 0.5384525\ttest: 0.5638134\tbest: 0.5638134 (14)\ttotal: 1.35s\tremaining: 1m 28s\n",
      "15:\tlearn: 0.5338861\ttest: 0.5613100\tbest: 0.5613100 (15)\ttotal: 1.41s\tremaining: 1m 26s\n",
      "16:\tlearn: 0.5285032\ttest: 0.5572926\tbest: 0.5572926 (16)\ttotal: 1.5s\tremaining: 1m 27s\n",
      "17:\tlearn: 0.5235155\ttest: 0.5542770\tbest: 0.5542770 (17)\ttotal: 1.6s\tremaining: 1m 27s\n",
      "18:\tlearn: 0.5194608\ttest: 0.5518391\tbest: 0.5518391 (18)\ttotal: 1.69s\tremaining: 1m 27s\n",
      "19:\tlearn: 0.5165044\ttest: 0.5495355\tbest: 0.5495355 (19)\ttotal: 1.73s\tremaining: 1m 24s\n",
      "20:\tlearn: 0.5119667\ttest: 0.5464442\tbest: 0.5464442 (20)\ttotal: 1.83s\tremaining: 1m 25s\n",
      "21:\tlearn: 0.5079922\ttest: 0.5438353\tbest: 0.5438353 (21)\ttotal: 1.92s\tremaining: 1m 25s\n",
      "22:\tlearn: 0.5033114\ttest: 0.5407266\tbest: 0.5407266 (22)\ttotal: 2.01s\tremaining: 1m 25s\n",
      "23:\tlearn: 0.4995428\ttest: 0.5379576\tbest: 0.5379576 (23)\ttotal: 2.11s\tremaining: 1m 25s\n",
      "24:\tlearn: 0.4961121\ttest: 0.5363319\tbest: 0.5363319 (24)\ttotal: 2.2s\tremaining: 1m 25s\n",
      "25:\tlearn: 0.4935437\ttest: 0.5348586\tbest: 0.5348586 (25)\ttotal: 2.3s\tremaining: 1m 26s\n",
      "26:\tlearn: 0.4918175\ttest: 0.5332562\tbest: 0.5332562 (26)\ttotal: 2.34s\tremaining: 1m 24s\n",
      "27:\tlearn: 0.4894865\ttest: 0.5320601\tbest: 0.5320601 (27)\ttotal: 2.44s\tremaining: 1m 24s\n",
      "28:\tlearn: 0.4873762\ttest: 0.5307058\tbest: 0.5307058 (28)\ttotal: 2.53s\tremaining: 1m 24s\n",
      "29:\tlearn: 0.4851593\ttest: 0.5293426\tbest: 0.5293426 (29)\ttotal: 2.63s\tremaining: 1m 24s\n",
      "30:\tlearn: 0.4836189\ttest: 0.5289503\tbest: 0.5289503 (30)\ttotal: 2.71s\tremaining: 1m 24s\n",
      "31:\tlearn: 0.4801865\ttest: 0.5280296\tbest: 0.5280296 (31)\ttotal: 2.8s\tremaining: 1m 24s\n",
      "32:\tlearn: 0.4788346\ttest: 0.5281063\tbest: 0.5280296 (31)\ttotal: 2.9s\tremaining: 1m 24s\n",
      "33:\tlearn: 0.4766582\ttest: 0.5270862\tbest: 0.5270862 (33)\ttotal: 2.99s\tremaining: 1m 25s\n",
      "34:\tlearn: 0.4742161\ttest: 0.5255500\tbest: 0.5255500 (34)\ttotal: 3.09s\tremaining: 1m 25s\n",
      "35:\tlearn: 0.4721351\ttest: 0.5242495\tbest: 0.5242495 (35)\ttotal: 3.19s\tremaining: 1m 25s\n",
      "36:\tlearn: 0.4695697\ttest: 0.5230212\tbest: 0.5230212 (36)\ttotal: 3.29s\tremaining: 1m 25s\n",
      "37:\tlearn: 0.4680067\ttest: 0.5221717\tbest: 0.5221717 (37)\ttotal: 3.38s\tremaining: 1m 25s\n",
      "38:\tlearn: 0.4652605\ttest: 0.5204886\tbest: 0.5204886 (38)\ttotal: 3.48s\tremaining: 1m 25s\n",
      "39:\tlearn: 0.4630497\ttest: 0.5194851\tbest: 0.5194851 (39)\ttotal: 3.58s\tremaining: 1m 26s\n",
      "40:\tlearn: 0.4613026\ttest: 0.5189633\tbest: 0.5189633 (40)\ttotal: 3.68s\tremaining: 1m 26s\n",
      "41:\tlearn: 0.4594381\ttest: 0.5182803\tbest: 0.5182803 (41)\ttotal: 3.77s\tremaining: 1m 26s\n",
      "42:\tlearn: 0.4584372\ttest: 0.5181958\tbest: 0.5181958 (42)\ttotal: 3.87s\tremaining: 1m 26s\n",
      "43:\tlearn: 0.4567702\ttest: 0.5174297\tbest: 0.5174297 (43)\ttotal: 3.96s\tremaining: 1m 26s\n",
      "44:\tlearn: 0.4548205\ttest: 0.5169936\tbest: 0.5169936 (44)\ttotal: 4.06s\tremaining: 1m 26s\n",
      "45:\tlearn: 0.4528151\ttest: 0.5164767\tbest: 0.5164767 (45)\ttotal: 4.15s\tremaining: 1m 26s\n",
      "46:\tlearn: 0.4507158\ttest: 0.5159718\tbest: 0.5159718 (46)\ttotal: 4.25s\tremaining: 1m 26s\n",
      "47:\tlearn: 0.4497486\ttest: 0.5154238\tbest: 0.5154238 (47)\ttotal: 4.35s\tremaining: 1m 26s\n",
      "48:\tlearn: 0.4479358\ttest: 0.5142310\tbest: 0.5142310 (48)\ttotal: 4.45s\tremaining: 1m 26s\n",
      "49:\tlearn: 0.4470875\ttest: 0.5144706\tbest: 0.5142310 (48)\ttotal: 4.54s\tremaining: 1m 26s\n",
      "50:\tlearn: 0.4466609\ttest: 0.5139894\tbest: 0.5139894 (50)\ttotal: 4.58s\tremaining: 1m 25s\n",
      "51:\tlearn: 0.4461119\ttest: 0.5140900\tbest: 0.5139894 (50)\ttotal: 4.68s\tremaining: 1m 25s\n",
      "52:\tlearn: 0.4434737\ttest: 0.5131569\tbest: 0.5131569 (52)\ttotal: 4.78s\tremaining: 1m 25s\n",
      "53:\tlearn: 0.4419741\ttest: 0.5121898\tbest: 0.5121898 (53)\ttotal: 4.87s\tremaining: 1m 25s\n",
      "54:\tlearn: 0.4412759\ttest: 0.5117400\tbest: 0.5117400 (54)\ttotal: 4.97s\tremaining: 1m 25s\n",
      "55:\tlearn: 0.4397790\ttest: 0.5114968\tbest: 0.5114968 (55)\ttotal: 5.06s\tremaining: 1m 25s\n",
      "56:\tlearn: 0.4373451\ttest: 0.5107812\tbest: 0.5107812 (56)\ttotal: 5.16s\tremaining: 1m 25s\n",
      "57:\tlearn: 0.4356199\ttest: 0.5105529\tbest: 0.5105529 (57)\ttotal: 5.25s\tremaining: 1m 25s\n",
      "58:\tlearn: 0.4346702\ttest: 0.5104561\tbest: 0.5104561 (58)\ttotal: 5.35s\tremaining: 1m 25s\n",
      "59:\tlearn: 0.4336060\ttest: 0.5100969\tbest: 0.5100969 (59)\ttotal: 5.44s\tremaining: 1m 25s\n",
      "60:\tlearn: 0.4327974\ttest: 0.5101926\tbest: 0.5100969 (59)\ttotal: 5.54s\tremaining: 1m 25s\n",
      "61:\tlearn: 0.4316274\ttest: 0.5100201\tbest: 0.5100201 (61)\ttotal: 5.63s\tremaining: 1m 25s\n",
      "62:\tlearn: 0.4313755\ttest: 0.5099318\tbest: 0.5099318 (62)\ttotal: 5.66s\tremaining: 1m 24s\n",
      "63:\tlearn: 0.4307417\ttest: 0.5096622\tbest: 0.5096622 (63)\ttotal: 5.75s\tremaining: 1m 24s\n",
      "64:\tlearn: 0.4300723\ttest: 0.5093392\tbest: 0.5093392 (64)\ttotal: 5.85s\tremaining: 1m 24s\n",
      "65:\tlearn: 0.4296422\ttest: 0.5088310\tbest: 0.5088310 (65)\ttotal: 5.89s\tremaining: 1m 23s\n",
      "66:\tlearn: 0.4293703\ttest: 0.5088517\tbest: 0.5088310 (65)\ttotal: 5.99s\tremaining: 1m 23s\n",
      "67:\tlearn: 0.4283409\ttest: 0.5088370\tbest: 0.5088310 (65)\ttotal: 6.08s\tremaining: 1m 23s\n",
      "68:\tlearn: 0.4277672\ttest: 0.5088046\tbest: 0.5088046 (68)\ttotal: 6.18s\tremaining: 1m 23s\n",
      "69:\tlearn: 0.4270875\ttest: 0.5084483\tbest: 0.5084483 (69)\ttotal: 6.28s\tremaining: 1m 23s\n",
      "70:\tlearn: 0.4264423\ttest: 0.5081489\tbest: 0.5081489 (70)\ttotal: 6.34s\tremaining: 1m 22s\n",
      "71:\tlearn: 0.4258192\ttest: 0.5077529\tbest: 0.5077529 (71)\ttotal: 6.44s\tremaining: 1m 22s\n",
      "72:\tlearn: 0.4252834\ttest: 0.5078440\tbest: 0.5077529 (71)\ttotal: 6.53s\tremaining: 1m 22s\n",
      "73:\tlearn: 0.4250822\ttest: 0.5078813\tbest: 0.5077529 (71)\ttotal: 6.63s\tremaining: 1m 22s\n",
      "74:\tlearn: 0.4245707\ttest: 0.5077474\tbest: 0.5077474 (74)\ttotal: 6.72s\tremaining: 1m 22s\n",
      "75:\tlearn: 0.4231887\ttest: 0.5074463\tbest: 0.5074463 (75)\ttotal: 6.82s\tremaining: 1m 22s\n",
      "76:\tlearn: 0.4226380\ttest: 0.5073512\tbest: 0.5073512 (76)\ttotal: 6.91s\tremaining: 1m 22s\n",
      "77:\tlearn: 0.4218962\ttest: 0.5071052\tbest: 0.5071052 (77)\ttotal: 7s\tremaining: 1m 22s\n",
      "78:\tlearn: 0.4203999\ttest: 0.5058892\tbest: 0.5058892 (78)\ttotal: 7.1s\tremaining: 1m 22s\n",
      "79:\tlearn: 0.4193705\ttest: 0.5055677\tbest: 0.5055677 (79)\ttotal: 7.2s\tremaining: 1m 22s\n",
      "80:\tlearn: 0.4187249\ttest: 0.5057032\tbest: 0.5055677 (79)\ttotal: 7.29s\tremaining: 1m 22s\n",
      "81:\tlearn: 0.4177607\ttest: 0.5052989\tbest: 0.5052989 (81)\ttotal: 7.39s\tremaining: 1m 22s\n",
      "82:\tlearn: 0.4168054\ttest: 0.5055744\tbest: 0.5052989 (81)\ttotal: 7.49s\tremaining: 1m 22s\n",
      "83:\tlearn: 0.4157934\ttest: 0.5053482\tbest: 0.5052989 (81)\ttotal: 7.58s\tremaining: 1m 22s\n",
      "84:\tlearn: 0.4152233\ttest: 0.5052548\tbest: 0.5052548 (84)\ttotal: 7.68s\tremaining: 1m 22s\n",
      "85:\tlearn: 0.4144571\ttest: 0.5046210\tbest: 0.5046210 (85)\ttotal: 7.78s\tremaining: 1m 22s\n",
      "86:\tlearn: 0.4126341\ttest: 0.5044898\tbest: 0.5044898 (86)\ttotal: 7.87s\tremaining: 1m 22s\n",
      "87:\tlearn: 0.4116079\ttest: 0.5039185\tbest: 0.5039185 (87)\ttotal: 7.97s\tremaining: 1m 22s\n",
      "88:\tlearn: 0.4108804\ttest: 0.5034517\tbest: 0.5034517 (88)\ttotal: 8.07s\tremaining: 1m 22s\n",
      "89:\tlearn: 0.4104296\ttest: 0.5033118\tbest: 0.5033118 (89)\ttotal: 8.17s\tremaining: 1m 22s\n",
      "90:\tlearn: 0.4098777\ttest: 0.5033090\tbest: 0.5033090 (90)\ttotal: 8.26s\tremaining: 1m 22s\n",
      "91:\tlearn: 0.4091446\ttest: 0.5031400\tbest: 0.5031400 (91)\ttotal: 8.36s\tremaining: 1m 22s\n",
      "92:\tlearn: 0.4078480\ttest: 0.5032106\tbest: 0.5031400 (91)\ttotal: 8.46s\tremaining: 1m 22s\n",
      "93:\tlearn: 0.4068931\ttest: 0.5027568\tbest: 0.5027568 (93)\ttotal: 8.56s\tremaining: 1m 22s\n",
      "94:\tlearn: 0.4058402\ttest: 0.5020819\tbest: 0.5020819 (94)\ttotal: 8.66s\tremaining: 1m 22s\n",
      "95:\tlearn: 0.4056676\ttest: 0.5018540\tbest: 0.5018540 (95)\ttotal: 8.72s\tremaining: 1m 22s\n",
      "96:\tlearn: 0.4043145\ttest: 0.5015102\tbest: 0.5015102 (96)\ttotal: 8.81s\tremaining: 1m 22s\n",
      "97:\tlearn: 0.4041059\ttest: 0.5013336\tbest: 0.5013336 (97)\ttotal: 8.87s\tremaining: 1m 21s\n",
      "98:\tlearn: 0.4039890\ttest: 0.5011694\tbest: 0.5011694 (98)\ttotal: 8.93s\tremaining: 1m 21s\n",
      "99:\tlearn: 0.4038346\ttest: 0.5009693\tbest: 0.5009693 (99)\ttotal: 8.97s\tremaining: 1m 20s\n",
      "100:\tlearn: 0.4032561\ttest: 0.5008706\tbest: 0.5008706 (100)\ttotal: 9.06s\tremaining: 1m 20s\n",
      "101:\tlearn: 0.4030138\ttest: 0.5007749\tbest: 0.5007749 (101)\ttotal: 9.14s\tremaining: 1m 20s\n",
      "102:\tlearn: 0.4026476\ttest: 0.5004391\tbest: 0.5004391 (102)\ttotal: 9.18s\tremaining: 1m 19s\n",
      "103:\tlearn: 0.4018291\ttest: 0.5002923\tbest: 0.5002923 (103)\ttotal: 9.28s\tremaining: 1m 19s\n",
      "104:\tlearn: 0.4000366\ttest: 0.4993635\tbest: 0.4993635 (104)\ttotal: 9.38s\tremaining: 1m 19s\n",
      "105:\tlearn: 0.3996381\ttest: 0.4990355\tbest: 0.4990355 (105)\ttotal: 9.46s\tremaining: 1m 19s\n",
      "106:\tlearn: 0.3988894\ttest: 0.4989035\tbest: 0.4989035 (106)\ttotal: 9.55s\tremaining: 1m 19s\n",
      "107:\tlearn: 0.3979066\ttest: 0.4985596\tbest: 0.4985596 (107)\ttotal: 9.65s\tremaining: 1m 19s\n",
      "108:\tlearn: 0.3967697\ttest: 0.4983866\tbest: 0.4983866 (108)\ttotal: 9.75s\tremaining: 1m 19s\n",
      "109:\tlearn: 0.3963060\ttest: 0.4985737\tbest: 0.4983866 (108)\ttotal: 9.85s\tremaining: 1m 19s\n",
      "110:\tlearn: 0.3956676\ttest: 0.4985968\tbest: 0.4983866 (108)\ttotal: 9.95s\tremaining: 1m 19s\n",
      "111:\tlearn: 0.3953204\ttest: 0.4985759\tbest: 0.4983866 (108)\ttotal: 10s\tremaining: 1m 19s\n",
      "112:\tlearn: 0.3947434\ttest: 0.4985316\tbest: 0.4983866 (108)\ttotal: 10.1s\tremaining: 1m 19s\n",
      "113:\tlearn: 0.3942282\ttest: 0.4985302\tbest: 0.4983866 (108)\ttotal: 10.2s\tremaining: 1m 19s\n",
      "114:\tlearn: 0.3937946\ttest: 0.4984678\tbest: 0.4983866 (108)\ttotal: 10.3s\tremaining: 1m 19s\n",
      "115:\tlearn: 0.3928108\ttest: 0.4981524\tbest: 0.4981524 (115)\ttotal: 10.4s\tremaining: 1m 19s\n",
      "116:\tlearn: 0.3923664\ttest: 0.4981625\tbest: 0.4981524 (115)\ttotal: 10.5s\tremaining: 1m 19s\n",
      "117:\tlearn: 0.3915885\ttest: 0.4982099\tbest: 0.4981524 (115)\ttotal: 10.6s\tremaining: 1m 19s\n",
      "118:\tlearn: 0.3910990\ttest: 0.4983837\tbest: 0.4981524 (115)\ttotal: 10.7s\tremaining: 1m 19s\n",
      "119:\tlearn: 0.3903686\ttest: 0.4979467\tbest: 0.4979467 (119)\ttotal: 10.8s\tremaining: 1m 19s\n",
      "120:\tlearn: 0.3896608\ttest: 0.4976380\tbest: 0.4976380 (120)\ttotal: 10.9s\tremaining: 1m 19s\n",
      "121:\tlearn: 0.3893845\ttest: 0.4974905\tbest: 0.4974905 (121)\ttotal: 11s\tremaining: 1m 19s\n",
      "122:\tlearn: 0.3886221\ttest: 0.4976243\tbest: 0.4974905 (121)\ttotal: 11.1s\tremaining: 1m 19s\n",
      "123:\tlearn: 0.3881900\ttest: 0.4976320\tbest: 0.4974905 (121)\ttotal: 11.2s\tremaining: 1m 18s\n",
      "124:\tlearn: 0.3874177\ttest: 0.4975676\tbest: 0.4974905 (121)\ttotal: 11.3s\tremaining: 1m 18s\n",
      "125:\tlearn: 0.3873585\ttest: 0.4974975\tbest: 0.4974905 (121)\ttotal: 11.3s\tremaining: 1m 18s\n",
      "126:\tlearn: 0.3863225\ttest: 0.4972929\tbest: 0.4972929 (126)\ttotal: 11.4s\tremaining: 1m 18s\n",
      "127:\tlearn: 0.3861192\ttest: 0.4973281\tbest: 0.4972929 (126)\ttotal: 11.5s\tremaining: 1m 18s\n",
      "128:\tlearn: 0.3860217\ttest: 0.4972156\tbest: 0.4972156 (128)\ttotal: 11.5s\tremaining: 1m 17s\n",
      "129:\tlearn: 0.3850089\ttest: 0.4981973\tbest: 0.4972156 (128)\ttotal: 11.6s\tremaining: 1m 17s\n",
      "130:\tlearn: 0.3843596\ttest: 0.4981246\tbest: 0.4972156 (128)\ttotal: 11.7s\tremaining: 1m 17s\n",
      "131:\tlearn: 0.3832971\ttest: 0.4982626\tbest: 0.4972156 (128)\ttotal: 11.8s\tremaining: 1m 17s\n",
      "132:\tlearn: 0.3824203\ttest: 0.4980663\tbest: 0.4972156 (128)\ttotal: 11.9s\tremaining: 1m 17s\n",
      "133:\tlearn: 0.3820965\ttest: 0.4980908\tbest: 0.4972156 (128)\ttotal: 12s\tremaining: 1m 17s\n",
      "134:\tlearn: 0.3813385\ttest: 0.4980138\tbest: 0.4972156 (128)\ttotal: 12.1s\tremaining: 1m 17s\n",
      "135:\tlearn: 0.3800958\ttest: 0.4981793\tbest: 0.4972156 (128)\ttotal: 12.2s\tremaining: 1m 17s\n",
      "136:\tlearn: 0.3797182\ttest: 0.4981761\tbest: 0.4972156 (128)\ttotal: 12.3s\tremaining: 1m 17s\n",
      "137:\tlearn: 0.3790187\ttest: 0.4981766\tbest: 0.4972156 (128)\ttotal: 12.4s\tremaining: 1m 17s\n",
      "138:\tlearn: 0.3775599\ttest: 0.4974847\tbest: 0.4972156 (128)\ttotal: 12.5s\tremaining: 1m 17s\n",
      "139:\tlearn: 0.3775012\ttest: 0.4975154\tbest: 0.4972156 (128)\ttotal: 12.5s\tremaining: 1m 16s\n",
      "140:\tlearn: 0.3769266\ttest: 0.4977395\tbest: 0.4972156 (128)\ttotal: 12.6s\tremaining: 1m 16s\n",
      "141:\tlearn: 0.3764605\ttest: 0.4973820\tbest: 0.4972156 (128)\ttotal: 12.7s\tremaining: 1m 16s\n",
      "142:\tlearn: 0.3755934\ttest: 0.4973587\tbest: 0.4972156 (128)\ttotal: 12.8s\tremaining: 1m 16s\n",
      "143:\tlearn: 0.3753828\ttest: 0.4971418\tbest: 0.4971418 (143)\ttotal: 12.8s\tremaining: 1m 16s\n",
      "144:\tlearn: 0.3747864\ttest: 0.4974717\tbest: 0.4971418 (143)\ttotal: 12.9s\tremaining: 1m 16s\n",
      "145:\tlearn: 0.3743993\ttest: 0.4977558\tbest: 0.4971418 (143)\ttotal: 13s\tremaining: 1m 16s\n",
      "146:\tlearn: 0.3743952\ttest: 0.4977463\tbest: 0.4971418 (143)\ttotal: 13.1s\tremaining: 1m 15s\n",
      "147:\tlearn: 0.3736495\ttest: 0.4976073\tbest: 0.4971418 (143)\ttotal: 13.2s\tremaining: 1m 15s\n",
      "148:\tlearn: 0.3729077\ttest: 0.4974319\tbest: 0.4971418 (143)\ttotal: 13.3s\tremaining: 1m 15s\n",
      "149:\tlearn: 0.3724720\ttest: 0.4973846\tbest: 0.4971418 (143)\ttotal: 13.3s\tremaining: 1m 15s\n",
      "150:\tlearn: 0.3723106\ttest: 0.4973359\tbest: 0.4971418 (143)\ttotal: 13.4s\tremaining: 1m 15s\n",
      "151:\tlearn: 0.3718791\ttest: 0.4973401\tbest: 0.4971418 (143)\ttotal: 13.5s\tremaining: 1m 15s\n",
      "152:\tlearn: 0.3711649\ttest: 0.4977973\tbest: 0.4971418 (143)\ttotal: 13.6s\tremaining: 1m 15s\n",
      "153:\tlearn: 0.3704408\ttest: 0.4973552\tbest: 0.4971418 (143)\ttotal: 13.7s\tremaining: 1m 15s\n",
      "154:\tlearn: 0.3695232\ttest: 0.4974416\tbest: 0.4971418 (143)\ttotal: 13.8s\tremaining: 1m 15s\n",
      "155:\tlearn: 0.3683819\ttest: 0.4972252\tbest: 0.4971418 (143)\ttotal: 13.9s\tremaining: 1m 15s\n",
      "156:\tlearn: 0.3677909\ttest: 0.4969020\tbest: 0.4969020 (156)\ttotal: 14s\tremaining: 1m 15s\n",
      "157:\tlearn: 0.3668199\ttest: 0.4968671\tbest: 0.4968671 (157)\ttotal: 14.1s\tremaining: 1m 14s\n",
      "158:\tlearn: 0.3665096\ttest: 0.4970460\tbest: 0.4968671 (157)\ttotal: 14.2s\tremaining: 1m 14s\n",
      "159:\tlearn: 0.3658883\ttest: 0.4970470\tbest: 0.4968671 (157)\ttotal: 14.3s\tremaining: 1m 14s\n",
      "160:\tlearn: 0.3653288\ttest: 0.4971055\tbest: 0.4968671 (157)\ttotal: 14.4s\tremaining: 1m 14s\n",
      "161:\tlearn: 0.3647450\ttest: 0.4971976\tbest: 0.4968671 (157)\ttotal: 14.4s\tremaining: 1m 14s\n",
      "162:\tlearn: 0.3642468\ttest: 0.4971829\tbest: 0.4968671 (157)\ttotal: 14.5s\tremaining: 1m 14s\n",
      "163:\tlearn: 0.3636039\ttest: 0.4970414\tbest: 0.4968671 (157)\ttotal: 14.6s\tremaining: 1m 14s\n",
      "164:\tlearn: 0.3629564\ttest: 0.4969160\tbest: 0.4968671 (157)\ttotal: 14.7s\tremaining: 1m 14s\n",
      "165:\tlearn: 0.3620247\ttest: 0.4967693\tbest: 0.4967693 (165)\ttotal: 14.8s\tremaining: 1m 14s\n",
      "166:\tlearn: 0.3618832\ttest: 0.4966701\tbest: 0.4966701 (166)\ttotal: 14.9s\tremaining: 1m 14s\n",
      "167:\tlearn: 0.3611054\ttest: 0.4974756\tbest: 0.4966701 (166)\ttotal: 15s\tremaining: 1m 14s\n",
      "168:\tlearn: 0.3599818\ttest: 0.4966500\tbest: 0.4966500 (168)\ttotal: 15.1s\tremaining: 1m 14s\n",
      "169:\tlearn: 0.3594127\ttest: 0.4964610\tbest: 0.4964610 (169)\ttotal: 15.2s\tremaining: 1m 14s\n",
      "170:\tlearn: 0.3589717\ttest: 0.4964123\tbest: 0.4964123 (170)\ttotal: 15.3s\tremaining: 1m 14s\n",
      "171:\tlearn: 0.3580763\ttest: 0.4968880\tbest: 0.4964123 (170)\ttotal: 15.4s\tremaining: 1m 14s\n",
      "172:\tlearn: 0.3577198\ttest: 0.4969223\tbest: 0.4964123 (170)\ttotal: 15.5s\tremaining: 1m 14s\n",
      "173:\tlearn: 0.3571976\ttest: 0.4969158\tbest: 0.4964123 (170)\ttotal: 15.6s\tremaining: 1m 14s\n",
      "174:\tlearn: 0.3564440\ttest: 0.4968489\tbest: 0.4964123 (170)\ttotal: 15.7s\tremaining: 1m 14s\n",
      "175:\tlearn: 0.3555158\ttest: 0.4962438\tbest: 0.4962438 (175)\ttotal: 15.8s\tremaining: 1m 14s\n",
      "176:\tlearn: 0.3549460\ttest: 0.4963599\tbest: 0.4962438 (175)\ttotal: 15.9s\tremaining: 1m 13s\n",
      "177:\tlearn: 0.3544022\ttest: 0.4960791\tbest: 0.4960791 (177)\ttotal: 16s\tremaining: 1m 13s\n",
      "178:\tlearn: 0.3533812\ttest: 0.4961975\tbest: 0.4960791 (177)\ttotal: 16.1s\tremaining: 1m 13s\n",
      "179:\tlearn: 0.3519724\ttest: 0.4957822\tbest: 0.4957822 (179)\ttotal: 16.2s\tremaining: 1m 13s\n",
      "180:\tlearn: 0.3511760\ttest: 0.4959477\tbest: 0.4957822 (179)\ttotal: 16.3s\tremaining: 1m 13s\n",
      "181:\tlearn: 0.3506198\ttest: 0.4960828\tbest: 0.4957822 (179)\ttotal: 16.4s\tremaining: 1m 13s\n",
      "182:\tlearn: 0.3505249\ttest: 0.4959091\tbest: 0.4957822 (179)\ttotal: 16.4s\tremaining: 1m 13s\n",
      "183:\tlearn: 0.3497030\ttest: 0.4957333\tbest: 0.4957333 (183)\ttotal: 16.5s\tremaining: 1m 13s\n",
      "184:\tlearn: 0.3490935\ttest: 0.4955735\tbest: 0.4955735 (184)\ttotal: 16.6s\tremaining: 1m 13s\n",
      "185:\tlearn: 0.3480318\ttest: 0.4950205\tbest: 0.4950205 (185)\ttotal: 16.7s\tremaining: 1m 12s\n",
      "186:\tlearn: 0.3478400\ttest: 0.4949493\tbest: 0.4949493 (186)\ttotal: 16.8s\tremaining: 1m 12s\n",
      "187:\tlearn: 0.3466967\ttest: 0.4952508\tbest: 0.4949493 (186)\ttotal: 16.9s\tremaining: 1m 12s\n",
      "188:\tlearn: 0.3459733\ttest: 0.4951558\tbest: 0.4949493 (186)\ttotal: 17s\tremaining: 1m 12s\n",
      "189:\tlearn: 0.3456518\ttest: 0.4954014\tbest: 0.4949493 (186)\ttotal: 17.1s\tremaining: 1m 12s\n",
      "190:\tlearn: 0.3451953\ttest: 0.4952169\tbest: 0.4949493 (186)\ttotal: 17.2s\tremaining: 1m 12s\n",
      "191:\tlearn: 0.3446562\ttest: 0.4947838\tbest: 0.4947838 (191)\ttotal: 17.2s\tremaining: 1m 12s\n",
      "192:\tlearn: 0.3445070\ttest: 0.4948109\tbest: 0.4947838 (191)\ttotal: 17.3s\tremaining: 1m 12s\n",
      "193:\tlearn: 0.3439147\ttest: 0.4948836\tbest: 0.4947838 (191)\ttotal: 17.4s\tremaining: 1m 12s\n",
      "194:\tlearn: 0.3431071\ttest: 0.4945740\tbest: 0.4945740 (194)\ttotal: 17.5s\tremaining: 1m 12s\n",
      "195:\tlearn: 0.3423959\ttest: 0.4941526\tbest: 0.4941526 (195)\ttotal: 17.6s\tremaining: 1m 12s\n",
      "196:\tlearn: 0.3411756\ttest: 0.4942842\tbest: 0.4941526 (195)\ttotal: 17.7s\tremaining: 1m 12s\n",
      "197:\tlearn: 0.3407734\ttest: 0.4941722\tbest: 0.4941526 (195)\ttotal: 17.8s\tremaining: 1m 12s\n",
      "198:\tlearn: 0.3399342\ttest: 0.4940947\tbest: 0.4940947 (198)\ttotal: 17.9s\tremaining: 1m 12s\n",
      "199:\tlearn: 0.3388810\ttest: 0.4938393\tbest: 0.4938393 (199)\ttotal: 18s\tremaining: 1m 11s\n",
      "200:\tlearn: 0.3378998\ttest: 0.4940079\tbest: 0.4938393 (199)\ttotal: 18.1s\tremaining: 1m 11s\n",
      "201:\tlearn: 0.3375195\ttest: 0.4938691\tbest: 0.4938393 (199)\ttotal: 18.2s\tremaining: 1m 11s\n",
      "202:\tlearn: 0.3365342\ttest: 0.4942520\tbest: 0.4938393 (199)\ttotal: 18.3s\tremaining: 1m 11s\n",
      "203:\tlearn: 0.3352302\ttest: 0.4942121\tbest: 0.4938393 (199)\ttotal: 18.4s\tremaining: 1m 11s\n",
      "204:\tlearn: 0.3340970\ttest: 0.4938700\tbest: 0.4938393 (199)\ttotal: 18.5s\tremaining: 1m 11s\n",
      "205:\tlearn: 0.3328928\ttest: 0.4942520\tbest: 0.4938393 (199)\ttotal: 18.6s\tremaining: 1m 11s\n",
      "206:\tlearn: 0.3314582\ttest: 0.4933912\tbest: 0.4933912 (206)\ttotal: 18.7s\tremaining: 1m 11s\n",
      "207:\tlearn: 0.3300635\ttest: 0.4929738\tbest: 0.4929738 (207)\ttotal: 18.8s\tremaining: 1m 11s\n",
      "208:\tlearn: 0.3286850\ttest: 0.4932107\tbest: 0.4929738 (207)\ttotal: 18.9s\tremaining: 1m 11s\n",
      "209:\tlearn: 0.3271400\ttest: 0.4924256\tbest: 0.4924256 (209)\ttotal: 19s\tremaining: 1m 11s\n",
      "210:\tlearn: 0.3265548\ttest: 0.4920300\tbest: 0.4920300 (210)\ttotal: 19.1s\tremaining: 1m 11s\n",
      "211:\tlearn: 0.3262294\ttest: 0.4918438\tbest: 0.4918438 (211)\ttotal: 19.2s\tremaining: 1m 11s\n",
      "212:\tlearn: 0.3257830\ttest: 0.4917525\tbest: 0.4917525 (212)\ttotal: 19.3s\tremaining: 1m 11s\n",
      "213:\tlearn: 0.3249744\ttest: 0.4916260\tbest: 0.4916260 (213)\ttotal: 19.4s\tremaining: 1m 11s\n",
      "214:\tlearn: 0.3236189\ttest: 0.4921972\tbest: 0.4916260 (213)\ttotal: 19.4s\tremaining: 1m 11s\n",
      "215:\tlearn: 0.3227679\ttest: 0.4923302\tbest: 0.4916260 (213)\ttotal: 19.5s\tremaining: 1m 10s\n",
      "216:\tlearn: 0.3214981\ttest: 0.4926753\tbest: 0.4916260 (213)\ttotal: 19.6s\tremaining: 1m 10s\n",
      "217:\tlearn: 0.3208614\ttest: 0.4923955\tbest: 0.4916260 (213)\ttotal: 19.7s\tremaining: 1m 10s\n",
      "218:\tlearn: 0.3194620\ttest: 0.4930488\tbest: 0.4916260 (213)\ttotal: 19.8s\tremaining: 1m 10s\n",
      "219:\tlearn: 0.3189002\ttest: 0.4929605\tbest: 0.4916260 (213)\ttotal: 19.9s\tremaining: 1m 10s\n",
      "220:\tlearn: 0.3176617\ttest: 0.4929222\tbest: 0.4916260 (213)\ttotal: 20s\tremaining: 1m 10s\n",
      "221:\tlearn: 0.3171989\ttest: 0.4928904\tbest: 0.4916260 (213)\ttotal: 20.1s\tremaining: 1m 10s\n",
      "222:\tlearn: 0.3163457\ttest: 0.4928024\tbest: 0.4916260 (213)\ttotal: 20.2s\tremaining: 1m 10s\n",
      "223:\tlearn: 0.3151654\ttest: 0.4930021\tbest: 0.4916260 (213)\ttotal: 20.3s\tremaining: 1m 10s\n",
      "224:\tlearn: 0.3143937\ttest: 0.4933265\tbest: 0.4916260 (213)\ttotal: 20.4s\tremaining: 1m 10s\n",
      "225:\tlearn: 0.3131090\ttest: 0.4927786\tbest: 0.4916260 (213)\ttotal: 20.5s\tremaining: 1m 10s\n",
      "226:\tlearn: 0.3122359\ttest: 0.4926280\tbest: 0.4916260 (213)\ttotal: 20.6s\tremaining: 1m 10s\n",
      "227:\tlearn: 0.3115042\ttest: 0.4926764\tbest: 0.4916260 (213)\ttotal: 20.7s\tremaining: 1m 10s\n",
      "228:\tlearn: 0.3110491\ttest: 0.4922962\tbest: 0.4916260 (213)\ttotal: 20.8s\tremaining: 1m 9s\n",
      "229:\tlearn: 0.3097849\ttest: 0.4926662\tbest: 0.4916260 (213)\ttotal: 20.9s\tremaining: 1m 9s\n",
      "230:\tlearn: 0.3092513\ttest: 0.4926175\tbest: 0.4916260 (213)\ttotal: 21s\tremaining: 1m 9s\n",
      "231:\tlearn: 0.3091102\ttest: 0.4925373\tbest: 0.4916260 (213)\ttotal: 21s\tremaining: 1m 9s\n",
      "232:\tlearn: 0.3083659\ttest: 0.4922079\tbest: 0.4916260 (213)\ttotal: 21.1s\tremaining: 1m 9s\n",
      "233:\tlearn: 0.3078773\ttest: 0.4922374\tbest: 0.4916260 (213)\ttotal: 21.2s\tremaining: 1m 9s\n",
      "Stopped by overfitting detector  (20 iterations wait)\n",
      "\n",
      "bestTest = 0.4916260378\n",
      "bestIteration = 213\n",
      "\n",
      "Shrink model to first 214 iterations.\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "model_catboost = CatBoostClassifier(n_estimators=1000, \n",
    "                                    early_stopping_rounds=20)\n",
    "train_data = Pool(\n",
    "        data=X_train_raw,\n",
    "        label=y_train,\n",
    "        cat_features=categorical_feature_indices,\n",
    "        weight=calculate_sample_weights(y_train)\n",
    "    )\n",
    "\n",
    "eval_data = Pool(\n",
    "        data=X_valid_raw,\n",
    "        label=y_valid,\n",
    "        cat_features=categorical_feature_indices,\n",
    "        weight=calculate_sample_weights(y_valid),\n",
    "    )\n",
    "\n",
    "model_catboost.fit(X=train_data, \n",
    "                   eval_set=eval_data)\n",
    "\n",
    "preds_catboost = model_catboost.predict_proba(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21b9be01-ba30-4300-b3e0-f4fd43b55c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy GRANDE: 0.8520286396181385\n",
      "F1 Score GRANDE: 0.7104289281255574\n",
      "ROC AUC GRANDE: 0.8663591233258829\n",
      "\n",
      "\n",
      "Accuracy XGB: 0.7673031026252983\n",
      "F1 Score XGB: 0.6787340458159341\n",
      "ROC AUC XGB: 0.8000830316849913\n",
      "\n",
      "\n",
      "Accuracy CatBoost: 0.7869928400954654\n",
      "F1 Score CatBoost: 0.7046369469890426\n",
      "ROC AUC CatBoost: 0.8625913411247657\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if args['objective'] == 'binary':\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test, np.round(preds_grande[:,1]))\n",
    "    f1_score = sklearn.metrics.f1_score(y_test, np.round(preds_grande[:,1]), average='macro')\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(y_test, preds_grande[:,1], average='macro', multi_class='ovo')\n",
    "\n",
    "    print('Accuracy GRANDE:', accuracy)\n",
    "    print('F1 Score GRANDE:', f1_score)\n",
    "    print('ROC AUC GRANDE:', roc_auc)\n",
    "    print('\\n')\n",
    "\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test, np.round(preds_xgb[:,1]))\n",
    "    f1_score = sklearn.metrics.f1_score(y_test, np.round(preds_xgb[:,1]), average='macro')\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(y_test, preds_xgb[:,1], average='macro', multi_class='ovo')\n",
    "\n",
    "    print('Accuracy XGB:', accuracy)\n",
    "    print('F1 Score XGB:', f1_score)\n",
    "    print('ROC AUC XGB:', roc_auc)\n",
    "    print('\\n')\n",
    "\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test, np.round(preds_catboost[:,1]))\n",
    "    f1_score = sklearn.metrics.f1_score(y_test, np.round(preds_catboost[:,1]), average='macro')\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(y_test, preds_catboost[:,1], average='macro', multi_class='ovo')\n",
    "\n",
    "    print('Accuracy CatBoost:', accuracy)\n",
    "    print('F1 Score CatBoost:', f1_score)\n",
    "    print('ROC AUC CatBoost:', roc_auc)\n",
    "    print('\\n')\n",
    "elif args['objective'] == 'classification':\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test, np.argmax(preds_grande, axis=1))\n",
    "    f1_score = sklearn.metrics.f1_score(y_test, np.argmax(preds_grande, axis=1), average='macro')\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(y_test, preds_grande, average='macro', multi_class='ovo', labels=[i for i in range(preds_grande.shape[1])])\n",
    "\n",
    "    print('Accuracy GRANDE:', accuracy)\n",
    "    print('F1 Score GRANDE:', f1_score)\n",
    "    print('ROC AUC GRANDE:', roc_auc)\n",
    "    print('\\n')\n",
    "\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test, np.argmax(preds_xgb, axis=1))\n",
    "    f1_score = sklearn.metrics.f1_score(y_test, np.argmax(preds_xgb, axis=1), average='macro')\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(y_test, preds_xgb, average='macro', multi_class='ovo', labels=[i for i in range(preds_grande.shape[1])])\n",
    "\n",
    "    print('Accuracy XGB:', accuracy)\n",
    "    print('F1 Score XGB:', f1_score)\n",
    "    print('ROC AUC XGB:', roc_auc)\n",
    "    print('\\n')\n",
    "\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test, np.argmax(preds_catboost, axis=1))\n",
    "    f1_score = sklearn.metrics.f1_score(y_test, np.argmax(preds_catboost, axis=1), average='macro')\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(y_test, preds_catboost, average='macro', multi_class='ovo', labels=[i for i in range(preds_grande.shape[1])])\n",
    "\n",
    "    print('Accuracy CatBoost:', accuracy)\n",
    "    print('F1 Score CatBoost:', f1_score)\n",
    "    print('ROC AUC CatBoost:', roc_auc)\n",
    "    print('\\n')\n",
    "else:\n",
    "    mean_absolute_error = sklearn.metrics.mean_absolute_error(y_test, np.round(preds_grande[:,1]))\n",
    "    r2_score = sklearn.metrics.r2_score(y_test, np.round(preds_grande[:,1]), average='macro')\n",
    "\n",
    "    print('MAE GRANDE:', mean_absolute_error)\n",
    "    print('R2 Score GRANDE:', r2_score)\n",
    "    print('\\n')\n",
    "\n",
    "    mean_absolute_error = sklearn.metrics.mean_absolute_error(y_test, np.round(preds_xgb[:,1]))\n",
    "    r2_score = sklearn.metrics.r2_score(y_test, np.round(preds_xgb[:,1]), average='macro')\n",
    "\n",
    "    print('MAE XGB:', mean_absolute_error)\n",
    "    print('R2 Score XGB:', r2_score)\n",
    "    print('\\n')\n",
    "\n",
    "    mean_absolute_error = sklearn.metrics.mean_absolute_error(y_test, np.round(preds_catboost[:,1]))\n",
    "    r2_score = sklearn.metrics.r2_score(y_test, np.round(preds_catboost[:,1]), average='macro')\n",
    "\n",
    "    print('MAE CatBoost:', mean_absolute_error)\n",
    "    print('R2 Score CatBoost:', r2_score)\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
