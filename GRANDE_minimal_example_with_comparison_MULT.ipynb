{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf584ce8-8849-4a53-8ce9-2de8f9dd752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify GPU to use\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52b07238-f972-45df-86ce-a11cc11d72e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 400\n",
      "Validation set size: 100\n",
      "Test set size: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smarton/anaconda3/envs/GradientBasedTreeLearning/lib/python3.11/site-packages/openml/datasets/functions.py:438: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import openml\n",
    "import category_encoders as ce\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "# Load balance-scale dataset\n",
    "dataset = openml.datasets.get_dataset(11)\n",
    "X, y, categorical_indicator, attribute_names = dataset.get_data(target=dataset.default_target_attribute)\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Validation set size:\", len(X_valid))\n",
    "print(\"Test set size:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a22e5c9-16a8-44ab-b8fa-19344b93dd22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left-weight</th>\n",
       "      <th>left-distance</th>\n",
       "      <th>right-weight</th>\n",
       "      <th>right-distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     left-weight  left-distance  right-weight  right-distance\n",
       "538          5.0            2.0           3.0             4.0\n",
       "161          2.0            2.0           3.0             2.0\n",
       "541          5.0            2.0           4.0             2.0\n",
       "233          2.0            5.0           2.0             4.0\n",
       "232          2.0            5.0           2.0             3.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c846edc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = X_train.copy()\n",
    "X_valid_raw = X_valid.copy()\n",
    "X_test_raw = X_test.copy()\n",
    "\n",
    "low_cardinality_indices = []\n",
    "high_cardinality_indices = []\n",
    "\n",
    "categorical_feature_indices = []\n",
    "for column_index in range(X_train.shape[1]):\n",
    "    if categorical_indicator[column_index]:\n",
    "        categorical_feature_indices.append(column_index)\n",
    "        if len(X_train.iloc[:,column_index].unique()) < 10:\n",
    "            low_cardinality_indices.append(X_train.columns[column_index])\n",
    "        else:\n",
    "            high_cardinality_indices.append(X_train.columns[column_index])\n",
    "\n",
    "y_train = y_train.values.codes.astype(np.float64)\n",
    "y_valid = y_valid.values.codes.astype(np.float64)\n",
    "y_test = y_test.values.codes.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "830c0041",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.OrdinalEncoder(cols=X_train.columns[categorical_feature_indices])\n",
    "encoder.fit(X_train)\n",
    "X_train = encoder.transform(X_train).astype(np.float64)\n",
    "X_valid = encoder.transform(X_valid).astype(np.float64)\n",
    "X_test = encoder.transform(X_test).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf0a93c2-e9a4-4fa5-a7f6-44689dd07d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 15:18:20.810814: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-02 15:18:21.974436: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/smarton/anaconda3/envs/GradientBasedTreeLearning/lib/python3.11/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 15:18:24.770999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46340 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:c1:00.0, compute capability: 8.6\n",
      "2023-11-02 15:18:28.745092: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x22cc1d60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-02 15:18:28.745153: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2023-11-02 15:18:28.766349: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-02 15:18:30.021844: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8801\n",
      "2023-11-02 15:18:31.170344: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 9s 381ms/step - loss: 1.0820 - val_loss: 1.0537\n",
      "Epoch 2/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.0368 - val_loss: 1.0119\n",
      "Epoch 3/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.9938 - val_loss: 0.9703\n",
      "Epoch 4/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9512 - val_loss: 0.9289\n",
      "Epoch 5/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9096 - val_loss: 0.8887\n",
      "Epoch 6/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.8697 - val_loss: 0.8502\n",
      "Epoch 7/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.8316 - val_loss: 0.8138\n",
      "Epoch 8/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.7954 - val_loss: 0.7793\n",
      "Epoch 9/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.7608 - val_loss: 0.7463\n",
      "Epoch 10/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.7267 - val_loss: 0.7150\n",
      "Epoch 11/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6948 - val_loss: 0.6854\n",
      "Epoch 12/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.6644 - val_loss: 0.6564\n",
      "Epoch 13/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.6369 - val_loss: 0.6301\n",
      "Epoch 14/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.6104 - val_loss: 0.6046\n",
      "Epoch 15/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.5859 - val_loss: 0.5830\n",
      "Epoch 16/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.5633 - val_loss: 0.5622\n",
      "Epoch 17/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.5424 - val_loss: 0.5431\n",
      "Epoch 18/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.5232 - val_loss: 0.5261\n",
      "Epoch 19/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.5067 - val_loss: 0.5131\n",
      "Epoch 20/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4928 - val_loss: 0.5008\n",
      "Epoch 21/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4779 - val_loss: 0.4893\n",
      "Epoch 22/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4659 - val_loss: 0.4783\n",
      "Epoch 23/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4537 - val_loss: 0.4676\n",
      "Epoch 24/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4429 - val_loss: 0.4586\n",
      "Epoch 25/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4328 - val_loss: 0.4503\n",
      "Epoch 26/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4238 - val_loss: 0.4436\n",
      "Epoch 27/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4146 - val_loss: 0.4344\n",
      "Epoch 28/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4063 - val_loss: 0.4322\n",
      "Epoch 29/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3998 - val_loss: 0.4215\n",
      "Epoch 30/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3908 - val_loss: 0.4196\n",
      "Epoch 31/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3846 - val_loss: 0.4120\n",
      "Epoch 32/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3773 - val_loss: 0.4073\n",
      "Epoch 33/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3720 - val_loss: 0.4027\n",
      "Epoch 34/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3649 - val_loss: 0.3978\n",
      "Epoch 35/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.3597 - val_loss: 0.3938\n",
      "Epoch 36/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3549 - val_loss: 0.3914\n",
      "Epoch 37/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3493 - val_loss: 0.3876\n",
      "Epoch 38/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3449 - val_loss: 0.3819\n",
      "Epoch 39/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3389 - val_loss: 0.3794\n",
      "Epoch 40/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3351 - val_loss: 0.3751\n",
      "Epoch 41/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3309 - val_loss: 0.3726\n",
      "Epoch 42/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3269 - val_loss: 0.3705\n",
      "Epoch 43/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3227 - val_loss: 0.3667\n",
      "Epoch 44/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3187 - val_loss: 0.3671\n",
      "Epoch 45/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3155 - val_loss: 0.3629\n",
      "Epoch 46/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.3119 - val_loss: 0.3596\n",
      "Epoch 47/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3088 - val_loss: 0.3554\n",
      "Epoch 48/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3057 - val_loss: 0.3551\n",
      "Epoch 49/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3021 - val_loss: 0.3522\n",
      "Epoch 50/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2985 - val_loss: 0.3477\n",
      "Epoch 51/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2943 - val_loss: 0.3456\n",
      "Epoch 52/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.2925 - val_loss: 0.3477\n",
      "Epoch 53/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2898 - val_loss: 0.3430\n",
      "Epoch 54/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2866 - val_loss: 0.3422\n",
      "Epoch 55/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.2841 - val_loss: 0.3387\n",
      "Epoch 56/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.2819 - val_loss: 0.3385\n",
      "Epoch 57/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2795 - val_loss: 0.3369\n",
      "Epoch 58/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.2762 - val_loss: 0.3311\n",
      "Epoch 59/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2730 - val_loss: 0.3323\n",
      "Epoch 60/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2732 - val_loss: 0.3276\n",
      "Epoch 61/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.2677 - val_loss: 0.3259\n",
      "Epoch 62/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.2661 - val_loss: 0.3288\n",
      "Epoch 63/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.2651 - val_loss: 0.3206\n",
      "Epoch 64/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2623 - val_loss: 0.3221\n",
      "Epoch 65/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.2586 - val_loss: 0.3180\n",
      "Epoch 66/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.2565 - val_loss: 0.3203\n",
      "Epoch 67/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.2550 - val_loss: 0.3156\n",
      "Epoch 68/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2518 - val_loss: 0.3148\n",
      "Epoch 69/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2511 - val_loss: 0.3118\n",
      "Epoch 70/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2476 - val_loss: 0.3099\n",
      "Epoch 71/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.2460 - val_loss: 0.3081\n",
      "Epoch 72/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.2426 - val_loss: 0.3070\n",
      "Epoch 73/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.2424 - val_loss: 0.3048\n",
      "Epoch 74/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2403 - val_loss: 0.3025\n",
      "Epoch 75/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2385 - val_loss: 0.3019\n",
      "Epoch 76/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.2349 - val_loss: 0.2993\n",
      "Epoch 77/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2352 - val_loss: 0.2989\n",
      "Epoch 78/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2311 - val_loss: 0.2972\n",
      "Epoch 79/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.2292 - val_loss: 0.2956\n",
      "Epoch 80/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.2280 - val_loss: 0.2947\n",
      "Epoch 81/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.2268 - val_loss: 0.2910\n",
      "Epoch 82/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2248 - val_loss: 0.2896\n",
      "Epoch 83/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2227 - val_loss: 0.2941\n",
      "Epoch 84/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2217 - val_loss: 0.2841\n",
      "Epoch 85/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2193 - val_loss: 0.2867\n",
      "Epoch 86/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.2182 - val_loss: 0.2801\n",
      "Epoch 87/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2171 - val_loss: 0.2813\n",
      "Epoch 88/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.2140 - val_loss: 0.2823\n",
      "Epoch 89/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2141 - val_loss: 0.2809\n",
      "Epoch 90/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2114 - val_loss: 0.2824\n",
      "Epoch 91/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2089 - val_loss: 0.2783\n",
      "Epoch 92/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2082 - val_loss: 0.2800\n",
      "Epoch 93/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2065 - val_loss: 0.2782\n",
      "Epoch 94/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2055 - val_loss: 0.2800\n",
      "Epoch 95/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2029 - val_loss: 0.2725\n",
      "Epoch 96/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2017 - val_loss: 0.2715\n",
      "Epoch 97/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2005 - val_loss: 0.2719\n",
      "Epoch 98/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1979 - val_loss: 0.2678\n",
      "Epoch 99/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1961 - val_loss: 0.2684\n",
      "Epoch 100/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1955 - val_loss: 0.2713\n",
      "Epoch 101/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1951 - val_loss: 0.2724\n",
      "Epoch 102/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1921 - val_loss: 0.2661\n",
      "Epoch 103/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1899 - val_loss: 0.2659\n",
      "Epoch 104/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.1909 - val_loss: 0.2627\n",
      "Epoch 105/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1885 - val_loss: 0.2603\n",
      "Epoch 106/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1868 - val_loss: 0.2654\n",
      "Epoch 107/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1863 - val_loss: 0.2583\n",
      "Epoch 108/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1842 - val_loss: 0.2609\n",
      "Epoch 109/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1848 - val_loss: 0.2573\n",
      "Epoch 110/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1829 - val_loss: 0.2578\n",
      "Epoch 111/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1817 - val_loss: 0.2576\n",
      "Epoch 112/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1785 - val_loss: 0.2590\n",
      "Epoch 113/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1777 - val_loss: 0.2563\n",
      "Epoch 114/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1776 - val_loss: 0.2511\n",
      "Epoch 115/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1756 - val_loss: 0.2554\n",
      "Epoch 116/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1747 - val_loss: 0.2506\n",
      "Epoch 117/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1725 - val_loss: 0.2481\n",
      "Epoch 118/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1700 - val_loss: 0.2498\n",
      "Epoch 119/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.1681 - val_loss: 0.2454\n",
      "Epoch 120/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1673 - val_loss: 0.2466\n",
      "Epoch 121/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.1675 - val_loss: 0.2485\n",
      "Epoch 122/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1665 - val_loss: 0.2404\n",
      "Epoch 123/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1657 - val_loss: 0.2470\n",
      "Epoch 124/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1648 - val_loss: 0.2434\n",
      "Epoch 125/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1638 - val_loss: 0.2395\n",
      "Epoch 126/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1615 - val_loss: 0.2431\n",
      "Epoch 127/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1615 - val_loss: 0.2447\n",
      "Epoch 128/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1617 - val_loss: 0.2402\n",
      "Epoch 129/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1583 - val_loss: 0.2444\n",
      "Epoch 130/1000\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.1585 - val_loss: 0.2376\n",
      "Epoch 131/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1572 - val_loss: 0.2331\n",
      "Epoch 132/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1566 - val_loss: 0.2432\n",
      "Epoch 133/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1542 - val_loss: 0.2355\n",
      "Epoch 134/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.1535 - val_loss: 0.2415\n",
      "Epoch 135/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1532 - val_loss: 0.2292\n",
      "Epoch 136/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.1505 - val_loss: 0.2323\n",
      "Epoch 137/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1510 - val_loss: 0.2348\n",
      "Epoch 138/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1486 - val_loss: 0.2355\n",
      "Epoch 139/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1473 - val_loss: 0.2417\n",
      "Epoch 140/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1483 - val_loss: 0.2278\n",
      "Epoch 141/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1466 - val_loss: 0.2297\n",
      "Epoch 142/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1442 - val_loss: 0.2303\n",
      "Epoch 143/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1418 - val_loss: 0.2386\n",
      "Epoch 144/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1436 - val_loss: 0.2287\n",
      "Epoch 145/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1428 - val_loss: 0.2379\n",
      "Epoch 146/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1445 - val_loss: 0.2420\n",
      "Epoch 147/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1460 - val_loss: 0.2237\n",
      "Epoch 148/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1406 - val_loss: 0.2285\n",
      "Epoch 149/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1387 - val_loss: 0.2294\n",
      "Epoch 150/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1357 - val_loss: 0.2271\n",
      "Epoch 151/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1348 - val_loss: 0.2257\n",
      "Epoch 152/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1350 - val_loss: 0.2226\n",
      "Epoch 153/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1330 - val_loss: 0.2195\n",
      "Epoch 154/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1330 - val_loss: 0.2299\n",
      "Epoch 155/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.1334 - val_loss: 0.2333\n",
      "Epoch 156/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1320 - val_loss: 0.2237\n",
      "Epoch 157/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1304 - val_loss: 0.2209\n",
      "Epoch 158/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1283 - val_loss: 0.2219\n",
      "Epoch 159/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1291 - val_loss: 0.2258\n",
      "Epoch 160/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1281 - val_loss: 0.2230\n",
      "Epoch 161/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1281 - val_loss: 0.2210\n",
      "Epoch 162/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1239 - val_loss: 0.2191\n",
      "Epoch 163/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1246 - val_loss: 0.2292\n",
      "Epoch 164/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1272 - val_loss: 0.2321\n",
      "Epoch 165/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1266 - val_loss: 0.2232\n",
      "Epoch 166/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1234 - val_loss: 0.2261\n",
      "Epoch 167/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1207 - val_loss: 0.2212\n",
      "Epoch 168/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1196 - val_loss: 0.2323\n",
      "Epoch 169/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.1225 - val_loss: 0.2333\n",
      "Epoch 170/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1209 - val_loss: 0.2257\n",
      "Epoch 171/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1192 - val_loss: 0.2355\n",
      "Epoch 172/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1161 - val_loss: 0.2341\n",
      "Epoch 173/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1149 - val_loss: 0.2283\n",
      "Epoch 174/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1165 - val_loss: 0.2395\n",
      "Epoch 175/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.1181 - val_loss: 0.2201\n",
      "Epoch 176/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1140 - val_loss: 0.2266\n",
      "Epoch 177/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1117 - val_loss: 0.2292\n",
      "Epoch 178/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1120 - val_loss: 0.2129\n",
      "Epoch 179/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1105 - val_loss: 0.2329\n",
      "Epoch 180/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1117 - val_loss: 0.2328\n",
      "Epoch 181/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1100 - val_loss: 0.2206\n",
      "Epoch 182/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1118 - val_loss: 0.2272\n",
      "Epoch 183/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1063 - val_loss: 0.2360\n",
      "Epoch 184/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1070 - val_loss: 0.2390\n",
      "Epoch 185/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1071 - val_loss: 0.2381\n",
      "Epoch 186/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1055 - val_loss: 0.2366\n",
      "Epoch 187/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1072 - val_loss: 0.2270\n",
      "Epoch 188/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1038 - val_loss: 0.2319\n",
      "Epoch 189/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1045 - val_loss: 0.2273\n",
      "Epoch 190/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1051 - val_loss: 0.2401\n",
      "Epoch 191/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.1032 - val_loss: 0.2236\n",
      "Epoch 192/1000\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0996 - val_loss: 0.2417\n",
      "Epoch 193/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1033 - val_loss: 0.2306\n",
      "Epoch 194/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0959 - val_loss: 0.2430\n",
      "Epoch 195/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0968 - val_loss: 0.2264\n",
      "Epoch 196/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1025 - val_loss: 0.2288\n",
      "Epoch 197/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1016 - val_loss: 0.2237\n",
      "Epoch 198/1000\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.1026 - val_loss: 0.2364\n",
      "Epoch 199/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0981 - val_loss: 0.2262\n",
      "Epoch 200/1000\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1002 - val_loss: 0.2372\n",
      "Epoch 201/1000\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0947 - val_loss: 0.2304\n",
      "Epoch 202/1000\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0931 - val_loss: 0.2386\n",
      "Epoch 203/1000\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0965 - val_loss: 0.2356\n"
     ]
    }
   ],
   "source": [
    "from GRANDE import GRANDE\n",
    "\n",
    "params = {\n",
    "        'depth': 5,\n",
    "        'n_estimators': 2048,\n",
    "\n",
    "        'learning_rate_weights': 0.005,\n",
    "        'learning_rate_index': 0.01,\n",
    "        'learning_rate_values': 0.01,\n",
    "        'learning_rate_leaf': 0.01,\n",
    "\n",
    "        'optimizer': 'SWA',\n",
    "        'cosine_decay_steps': 0,\n",
    "\n",
    "        'initializer': 'RandomNormal',\n",
    "\n",
    "        'loss': 'crossentropy',\n",
    "        'focal_loss': False,\n",
    "        'temperature': 0.0,\n",
    "\n",
    "        'from_logits': True,\n",
    "        'apply_class_balancing': True,\n",
    "\n",
    "        'dropout': 0.0,\n",
    "\n",
    "        'selected_variables': 0.8,\n",
    "        'data_subset_fraction': 1.0,\n",
    "}\n",
    "\n",
    "args = {\n",
    "    'epochs': 1_000,\n",
    "    'early_stopping_epochs': 25,\n",
    "    'batch_size': 64,\n",
    "\n",
    "    'cat_idx': categorical_feature_indices,\n",
    "    'objective': 'classification',\n",
    "    \n",
    "    'metrics': ['F1'], # F1, Accuracy, R2\n",
    "    'random_seed': 42,\n",
    "    'verbose': 1,       \n",
    "}\n",
    "\n",
    "model_grande = GRANDE(params=params, args=args)\n",
    "\n",
    "model_grande.fit(X_train=X_train,\n",
    "          y_train=y_train,\n",
    "          X_val=X_valid,\n",
    "          y_val=y_valid)\n",
    "\n",
    "preds_grande = model_grande.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b251df9d-67f0-4dd1-a0cc-379621e33fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sample_weights(y_data):\n",
    "    class_weights = sklearn.utils.class_weight.compute_class_weight(class_weight = 'balanced', classes = np.unique(y_data), y = y_data)\n",
    "    #class_weights = class_weights/sum(class_weights)#    \n",
    "    sample_weights = sklearn.utils.class_weight.compute_sample_weight(class_weight = 'balanced', y =y_data)\n",
    "    #sample_weights = sample_weights/sum(class_weights)\n",
    "    return sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5d5f00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smarton/anaconda3/envs/GradientBasedTreeLearning/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:2667: UserWarning: n_quantiles (1000) is greater than the total number of samples (400). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "median = X_train.median(axis=0)\n",
    "X_train= X_train.fillna(median)\n",
    "X_vali = X_valid.fillna(median)\n",
    "X_test = X_test.fillna(median)\n",
    "\n",
    "encoder = ce.LeaveOneOutEncoder(cols=high_cardinality_indices)\n",
    "encoder.fit(X_train, y_train)\n",
    "X_train = encoder.transform(X_train)\n",
    "X_valid = encoder.transform(X_valid)\n",
    "X_test = encoder.transform(X_test)\n",
    "\n",
    "encoder = ce.OneHotEncoder(cols=low_cardinality_indices)\n",
    "encoder.fit(X_train)\n",
    "X_train = encoder.transform(X_train)\n",
    "X_valid = encoder.transform(X_valid)\n",
    "X_test = encoder.transform(X_test)\n",
    "\n",
    "median = X_train.median(axis=0)\n",
    "X_train = X_train.fillna(median)\n",
    "X_valid = X_valid.fillna(median)\n",
    "X_test = X_test.fillna(median)\n",
    "\n",
    "quantile_noise = 1e-4\n",
    "quantile_train = np.copy(X_train.values).astype(np.float64)\n",
    "np.random.seed(42)\n",
    "stds = np.std(quantile_train, axis=0, keepdims=True)\n",
    "noise_std = quantile_noise / np.maximum(stds, quantile_noise)\n",
    "quantile_train += noise_std * np.random.randn(*quantile_train.shape)       \n",
    "\n",
    "scaler = sklearn.preprocessing.QuantileTransformer(output_distribution='normal')\n",
    "scaler.fit(quantile_train)\n",
    "\n",
    "X_train = scaler.transform(X_train.values.astype(np.float64))\n",
    "X_valid = scaler.transform(X_valid.values.astype(np.float64))\n",
    "X_test = scaler.transform(X_test.values.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "361f7d9f-7e58-4bc1-8855-153b9e972742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:0.92906\n",
      "[1]\tvalidation_0-mlogloss:0.84543\n",
      "[2]\tvalidation_0-mlogloss:0.77895\n",
      "[3]\tvalidation_0-mlogloss:0.74425\n",
      "[4]\tvalidation_0-mlogloss:0.73254\n",
      "[5]\tvalidation_0-mlogloss:0.71118\n",
      "[6]\tvalidation_0-mlogloss:0.70206\n",
      "[7]\tvalidation_0-mlogloss:0.69809\n",
      "[8]\tvalidation_0-mlogloss:0.70716\n",
      "[9]\tvalidation_0-mlogloss:0.71560\n",
      "[10]\tvalidation_0-mlogloss:0.72703\n",
      "[11]\tvalidation_0-mlogloss:0.72930\n",
      "[12]\tvalidation_0-mlogloss:0.73781\n",
      "[13]\tvalidation_0-mlogloss:0.74436\n",
      "[14]\tvalidation_0-mlogloss:0.75612\n",
      "[15]\tvalidation_0-mlogloss:0.76647\n",
      "[16]\tvalidation_0-mlogloss:0.77294\n",
      "[17]\tvalidation_0-mlogloss:0.76826\n",
      "[18]\tvalidation_0-mlogloss:0.77106\n",
      "[19]\tvalidation_0-mlogloss:0.78535\n",
      "[20]\tvalidation_0-mlogloss:0.78614\n",
      "[21]\tvalidation_0-mlogloss:0.79861\n",
      "[22]\tvalidation_0-mlogloss:0.80108\n",
      "[23]\tvalidation_0-mlogloss:0.81176\n",
      "[24]\tvalidation_0-mlogloss:0.81198\n",
      "[25]\tvalidation_0-mlogloss:0.81683\n",
      "[26]\tvalidation_0-mlogloss:0.82233\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model_xgb = XGBClassifier(n_estimators=1000, early_stopping_rounds=20)\n",
    "model_xgb.fit(X_train, \n",
    "                y_train, \n",
    "                sample_weight=calculate_sample_weights(y_train), \n",
    "                eval_set=[(X_valid, y_valid)], \n",
    "                sample_weight_eval_set=[calculate_sample_weights(y_valid)]\n",
    "             )\n",
    "\n",
    "preds_xgb = model_xgb.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25016783",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.OrdinalEncoder(cols=X_train_raw.columns[categorical_feature_indices])\n",
    "encoder.fit(X_train_raw)\n",
    "X_train_raw = encoder.transform(X_train_raw)\n",
    "X_valid_raw = encoder.transform(X_valid_raw)\n",
    "X_test_raw = encoder.transform(X_test_raw)\n",
    "\n",
    "median = X_train_raw.median(axis=0)\n",
    "X_train_raw = X_train_raw.fillna(median)\n",
    "X_valid_raw = X_valid_raw.fillna(median)\n",
    "X_test_raw = X_test_raw.fillna(median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b23c67e-cdde-40c2-842a-61383e1a62d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.106015\n",
      "0:\tlearn: 1.0490346\ttest: 1.0632694\tbest: 1.0632694 (0)\ttotal: 46.9ms\tremaining: 46.9s\n",
      "1:\tlearn: 0.9981136\ttest: 1.0086553\tbest: 1.0086553 (1)\ttotal: 48.2ms\tremaining: 24s\n",
      "2:\tlearn: 0.9493243\ttest: 0.9615261\tbest: 0.9615261 (2)\ttotal: 49.7ms\tremaining: 16.5s\n",
      "3:\tlearn: 0.9089973\ttest: 0.9258129\tbest: 0.9258129 (3)\ttotal: 50.8ms\tremaining: 12.6s\n",
      "4:\tlearn: 0.8773156\ttest: 0.9026201\tbest: 0.9026201 (4)\ttotal: 52.1ms\tremaining: 10.4s\n",
      "5:\tlearn: 0.8428892\ttest: 0.8817201\tbest: 0.8817201 (5)\ttotal: 53.3ms\tremaining: 8.82s\n",
      "6:\tlearn: 0.8179774\ttest: 0.8639109\tbest: 0.8639109 (6)\ttotal: 54.8ms\tremaining: 7.77s\n",
      "7:\tlearn: 0.7867788\ttest: 0.8385414\tbest: 0.8385414 (7)\ttotal: 55.7ms\tremaining: 6.91s\n",
      "8:\tlearn: 0.7617402\ttest: 0.8156207\tbest: 0.8156207 (8)\ttotal: 56.9ms\tremaining: 6.26s\n",
      "9:\tlearn: 0.7363277\ttest: 0.7937842\tbest: 0.7937842 (9)\ttotal: 57.9ms\tremaining: 5.73s\n",
      "10:\tlearn: 0.7159307\ttest: 0.7786301\tbest: 0.7786301 (10)\ttotal: 58.8ms\tremaining: 5.29s\n",
      "11:\tlearn: 0.7000605\ttest: 0.7715548\tbest: 0.7715548 (11)\ttotal: 59.7ms\tremaining: 4.92s\n",
      "12:\tlearn: 0.6883598\ttest: 0.7589939\tbest: 0.7589939 (12)\ttotal: 60.5ms\tremaining: 4.59s\n",
      "13:\tlearn: 0.6778845\ttest: 0.7504221\tbest: 0.7504221 (13)\ttotal: 61.4ms\tremaining: 4.33s\n",
      "14:\tlearn: 0.6714652\ttest: 0.7455446\tbest: 0.7455446 (14)\ttotal: 61.9ms\tremaining: 4.07s\n",
      "15:\tlearn: 0.6538533\ttest: 0.7355449\tbest: 0.7355449 (15)\ttotal: 62.8ms\tremaining: 3.86s\n",
      "16:\tlearn: 0.6381894\ttest: 0.7245504\tbest: 0.7245504 (16)\ttotal: 63.9ms\tremaining: 3.69s\n",
      "17:\tlearn: 0.6324706\ttest: 0.7194577\tbest: 0.7194577 (17)\ttotal: 64.5ms\tremaining: 3.52s\n",
      "18:\tlearn: 0.6245506\ttest: 0.7126864\tbest: 0.7126864 (18)\ttotal: 65.1ms\tremaining: 3.36s\n",
      "19:\tlearn: 0.6094649\ttest: 0.7040337\tbest: 0.7040337 (19)\ttotal: 66ms\tremaining: 3.23s\n",
      "20:\tlearn: 0.5971472\ttest: 0.6978941\tbest: 0.6978941 (20)\ttotal: 66.7ms\tremaining: 3.11s\n",
      "21:\tlearn: 0.5850698\ttest: 0.6872102\tbest: 0.6872102 (21)\ttotal: 67.5ms\tremaining: 3s\n",
      "22:\tlearn: 0.5772163\ttest: 0.6835691\tbest: 0.6835691 (22)\ttotal: 68.8ms\tremaining: 2.92s\n",
      "23:\tlearn: 0.5623486\ttest: 0.6821599\tbest: 0.6821599 (23)\ttotal: 69.6ms\tremaining: 2.83s\n",
      "24:\tlearn: 0.5501289\ttest: 0.6734774\tbest: 0.6734774 (24)\ttotal: 70.8ms\tremaining: 2.76s\n",
      "25:\tlearn: 0.5391216\ttest: 0.6653700\tbest: 0.6653700 (25)\ttotal: 71.5ms\tremaining: 2.68s\n",
      "26:\tlearn: 0.5299837\ttest: 0.6603153\tbest: 0.6603153 (26)\ttotal: 72.3ms\tremaining: 2.6s\n",
      "27:\tlearn: 0.5171550\ttest: 0.6558189\tbest: 0.6558189 (27)\ttotal: 73.1ms\tremaining: 2.54s\n",
      "28:\tlearn: 0.5100945\ttest: 0.6532612\tbest: 0.6532612 (28)\ttotal: 73.8ms\tremaining: 2.47s\n",
      "29:\tlearn: 0.5000430\ttest: 0.6544895\tbest: 0.6532612 (28)\ttotal: 74.7ms\tremaining: 2.42s\n",
      "30:\tlearn: 0.4907201\ttest: 0.6529126\tbest: 0.6529126 (30)\ttotal: 75.5ms\tremaining: 2.36s\n",
      "31:\tlearn: 0.4827371\ttest: 0.6521201\tbest: 0.6521201 (31)\ttotal: 76.3ms\tremaining: 2.31s\n",
      "32:\tlearn: 0.4768118\ttest: 0.6488893\tbest: 0.6488893 (32)\ttotal: 77.1ms\tremaining: 2.26s\n",
      "33:\tlearn: 0.4693847\ttest: 0.6466417\tbest: 0.6466417 (33)\ttotal: 77.9ms\tremaining: 2.21s\n",
      "34:\tlearn: 0.4630932\ttest: 0.6435843\tbest: 0.6435843 (34)\ttotal: 78.6ms\tremaining: 2.17s\n",
      "35:\tlearn: 0.4552199\ttest: 0.6395041\tbest: 0.6395041 (35)\ttotal: 79.6ms\tremaining: 2.13s\n",
      "36:\tlearn: 0.4443714\ttest: 0.6367745\tbest: 0.6367745 (36)\ttotal: 80.2ms\tremaining: 2.09s\n",
      "37:\tlearn: 0.4377722\ttest: 0.6370233\tbest: 0.6367745 (36)\ttotal: 81.1ms\tremaining: 2.05s\n",
      "38:\tlearn: 0.4316221\ttest: 0.6349342\tbest: 0.6349342 (38)\ttotal: 82.2ms\tremaining: 2.03s\n",
      "39:\tlearn: 0.4245884\ttest: 0.6296966\tbest: 0.6296966 (39)\ttotal: 82.9ms\tremaining: 1.99s\n",
      "40:\tlearn: 0.4212981\ttest: 0.6291476\tbest: 0.6291476 (40)\ttotal: 83.7ms\tremaining: 1.96s\n",
      "41:\tlearn: 0.4151772\ttest: 0.6275823\tbest: 0.6275823 (41)\ttotal: 84.6ms\tremaining: 1.93s\n",
      "42:\tlearn: 0.4085568\ttest: 0.6247146\tbest: 0.6247146 (42)\ttotal: 85.4ms\tremaining: 1.9s\n",
      "43:\tlearn: 0.4012723\ttest: 0.6230498\tbest: 0.6230498 (43)\ttotal: 86.2ms\tremaining: 1.87s\n",
      "44:\tlearn: 0.3965581\ttest: 0.6185522\tbest: 0.6185522 (44)\ttotal: 87ms\tremaining: 1.84s\n",
      "45:\tlearn: 0.3906870\ttest: 0.6203548\tbest: 0.6185522 (44)\ttotal: 87.7ms\tremaining: 1.82s\n",
      "46:\tlearn: 0.3862025\ttest: 0.6185170\tbest: 0.6185170 (46)\ttotal: 88.4ms\tremaining: 1.79s\n",
      "47:\tlearn: 0.3814050\ttest: 0.6191841\tbest: 0.6185170 (46)\ttotal: 89.2ms\tremaining: 1.77s\n",
      "48:\tlearn: 0.3782025\ttest: 0.6186386\tbest: 0.6185170 (46)\ttotal: 89.8ms\tremaining: 1.74s\n",
      "49:\tlearn: 0.3730194\ttest: 0.6182683\tbest: 0.6182683 (49)\ttotal: 90.5ms\tremaining: 1.72s\n",
      "50:\tlearn: 0.3697137\ttest: 0.6196174\tbest: 0.6182683 (49)\ttotal: 91.5ms\tremaining: 1.7s\n",
      "51:\tlearn: 0.3637058\ttest: 0.6189350\tbest: 0.6182683 (49)\ttotal: 92.3ms\tremaining: 1.68s\n",
      "52:\tlearn: 0.3584447\ttest: 0.6212308\tbest: 0.6182683 (49)\ttotal: 93.1ms\tremaining: 1.66s\n",
      "53:\tlearn: 0.3497174\ttest: 0.6180271\tbest: 0.6180271 (53)\ttotal: 94ms\tremaining: 1.65s\n",
      "54:\tlearn: 0.3457180\ttest: 0.6183244\tbest: 0.6180271 (53)\ttotal: 94.7ms\tremaining: 1.63s\n",
      "55:\tlearn: 0.3425354\ttest: 0.6207255\tbest: 0.6180271 (53)\ttotal: 95.5ms\tremaining: 1.61s\n",
      "56:\tlearn: 0.3368542\ttest: 0.6162374\tbest: 0.6162374 (56)\ttotal: 96.2ms\tremaining: 1.59s\n",
      "57:\tlearn: 0.3316262\ttest: 0.6188520\tbest: 0.6162374 (56)\ttotal: 96.9ms\tremaining: 1.57s\n",
      "58:\tlearn: 0.3255566\ttest: 0.6120271\tbest: 0.6120271 (58)\ttotal: 97.9ms\tremaining: 1.56s\n",
      "59:\tlearn: 0.3222694\ttest: 0.6107498\tbest: 0.6107498 (59)\ttotal: 98.8ms\tremaining: 1.55s\n",
      "60:\tlearn: 0.3184668\ttest: 0.6072412\tbest: 0.6072412 (60)\ttotal: 99.7ms\tremaining: 1.53s\n",
      "61:\tlearn: 0.3146727\ttest: 0.6060594\tbest: 0.6060594 (61)\ttotal: 101ms\tremaining: 1.52s\n",
      "62:\tlearn: 0.3096085\ttest: 0.6033444\tbest: 0.6033444 (62)\ttotal: 101ms\tremaining: 1.51s\n",
      "63:\tlearn: 0.3064155\ttest: 0.6006286\tbest: 0.6006286 (63)\ttotal: 102ms\tremaining: 1.5s\n",
      "64:\tlearn: 0.3033682\ttest: 0.5976912\tbest: 0.5976912 (64)\ttotal: 103ms\tremaining: 1.49s\n",
      "65:\tlearn: 0.2994302\ttest: 0.5977032\tbest: 0.5976912 (64)\ttotal: 104ms\tremaining: 1.48s\n",
      "66:\tlearn: 0.2940040\ttest: 0.5957439\tbest: 0.5957439 (66)\ttotal: 105ms\tremaining: 1.46s\n",
      "67:\tlearn: 0.2912391\ttest: 0.5936835\tbest: 0.5936835 (67)\ttotal: 106ms\tremaining: 1.46s\n",
      "68:\tlearn: 0.2877755\ttest: 0.5926172\tbest: 0.5926172 (68)\ttotal: 107ms\tremaining: 1.44s\n",
      "69:\tlearn: 0.2837043\ttest: 0.5894699\tbest: 0.5894699 (69)\ttotal: 108ms\tremaining: 1.43s\n",
      "70:\tlearn: 0.2798531\ttest: 0.5871315\tbest: 0.5871315 (70)\ttotal: 108ms\tremaining: 1.42s\n",
      "71:\tlearn: 0.2766974\ttest: 0.5834539\tbest: 0.5834539 (71)\ttotal: 109ms\tremaining: 1.41s\n",
      "72:\tlearn: 0.2733347\ttest: 0.5817169\tbest: 0.5817169 (72)\ttotal: 110ms\tremaining: 1.4s\n",
      "73:\tlearn: 0.2707058\ttest: 0.5837019\tbest: 0.5817169 (72)\ttotal: 111ms\tremaining: 1.39s\n",
      "74:\tlearn: 0.2676788\ttest: 0.5823989\tbest: 0.5817169 (72)\ttotal: 112ms\tremaining: 1.38s\n",
      "75:\tlearn: 0.2650410\ttest: 0.5823255\tbest: 0.5817169 (72)\ttotal: 112ms\tremaining: 1.37s\n",
      "76:\tlearn: 0.2623592\ttest: 0.5835963\tbest: 0.5817169 (72)\ttotal: 113ms\tremaining: 1.36s\n",
      "77:\tlearn: 0.2597867\ttest: 0.5838944\tbest: 0.5817169 (72)\ttotal: 114ms\tremaining: 1.35s\n",
      "78:\tlearn: 0.2570547\ttest: 0.5872337\tbest: 0.5817169 (72)\ttotal: 115ms\tremaining: 1.34s\n",
      "79:\tlearn: 0.2543289\ttest: 0.5844890\tbest: 0.5817169 (72)\ttotal: 116ms\tremaining: 1.33s\n",
      "80:\tlearn: 0.2517924\ttest: 0.5887527\tbest: 0.5817169 (72)\ttotal: 116ms\tremaining: 1.32s\n",
      "81:\tlearn: 0.2496392\ttest: 0.5901883\tbest: 0.5817169 (72)\ttotal: 117ms\tremaining: 1.31s\n",
      "82:\tlearn: 0.2470284\ttest: 0.5908447\tbest: 0.5817169 (72)\ttotal: 118ms\tremaining: 1.3s\n",
      "83:\tlearn: 0.2446767\ttest: 0.5895447\tbest: 0.5817169 (72)\ttotal: 119ms\tremaining: 1.29s\n",
      "84:\tlearn: 0.2420297\ttest: 0.5907498\tbest: 0.5817169 (72)\ttotal: 119ms\tremaining: 1.28s\n",
      "85:\tlearn: 0.2396913\ttest: 0.5912199\tbest: 0.5817169 (72)\ttotal: 120ms\tremaining: 1.28s\n",
      "86:\tlearn: 0.2373851\ttest: 0.5938497\tbest: 0.5817169 (72)\ttotal: 121ms\tremaining: 1.27s\n",
      "87:\tlearn: 0.2343313\ttest: 0.5902858\tbest: 0.5817169 (72)\ttotal: 122ms\tremaining: 1.26s\n",
      "88:\tlearn: 0.2313769\ttest: 0.5895402\tbest: 0.5817169 (72)\ttotal: 123ms\tremaining: 1.25s\n",
      "89:\tlearn: 0.2285002\ttest: 0.5896463\tbest: 0.5817169 (72)\ttotal: 123ms\tremaining: 1.25s\n",
      "90:\tlearn: 0.2260068\ttest: 0.5880630\tbest: 0.5817169 (72)\ttotal: 124ms\tremaining: 1.24s\n",
      "91:\tlearn: 0.2239972\ttest: 0.5873528\tbest: 0.5817169 (72)\ttotal: 125ms\tremaining: 1.23s\n",
      "92:\tlearn: 0.2211751\ttest: 0.5859427\tbest: 0.5817169 (72)\ttotal: 126ms\tremaining: 1.23s\n",
      "Stopped by overfitting detector  (20 iterations wait)\n",
      "\n",
      "bestTest = 0.5817169143\n",
      "bestIteration = 72\n",
      "\n",
      "Shrink model to first 73 iterations.\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "model_catboost = CatBoostClassifier(n_estimators=1000, \n",
    "                                    early_stopping_rounds=20)\n",
    "train_data = Pool(\n",
    "        data=X_train_raw,\n",
    "        label=y_train,\n",
    "        cat_features=categorical_feature_indices,\n",
    "        weight=calculate_sample_weights(y_train)\n",
    "    )\n",
    "\n",
    "eval_data = Pool(\n",
    "        data=X_valid_raw,\n",
    "        label=y_valid,\n",
    "        cat_features=categorical_feature_indices,\n",
    "        weight=calculate_sample_weights(y_valid),\n",
    "    )\n",
    "\n",
    "model_catboost.fit(X=train_data, \n",
    "                   eval_set=eval_data)\n",
    "\n",
    "preds_catboost = model_catboost.predict_proba(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21b9be01-ba30-4300-b3e0-f4fd43b55c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy GRANDE: 0.904\n",
      "F1 Score GRANDE: 0.6338171091445427\n",
      "ROC AUC GRANDE: 0.9294532380818975\n",
      "\n",
      "\n",
      "Accuracy XGB: 0.768\n",
      "F1 Score XGB: 0.6161896745230079\n",
      "ROC AUC XGB: 0.7848764999766541\n",
      "\n",
      "\n",
      "Accuracy CatBoost: 0.792\n",
      "F1 Score CatBoost: 0.6638439468628149\n",
      "ROC AUC CatBoost: 0.866746042863146\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if args['objective'] == 'binary':\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test, np.round(preds_grande[:,1]))\n",
    "    f1_score = sklearn.metrics.f1_score(y_test, np.round(preds_grande[:,1]), average='macro')\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(y_test, preds_grande[:,1], average='macro', multi_class='ovo')\n",
    "\n",
    "    print('Accuracy GRANDE:', accuracy)\n",
    "    print('F1 Score GRANDE:', f1_score)\n",
    "    print('ROC AUC GRANDE:', roc_auc)\n",
    "    print('\\n')\n",
    "\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test, np.round(preds_xgb[:,1]))\n",
    "    f1_score = sklearn.metrics.f1_score(y_test, np.round(preds_xgb[:,1]), average='macro')\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(y_test, preds_xgb[:,1], average='macro', multi_class='ovo')\n",
    "\n",
    "    print('Accuracy XGB:', accuracy)\n",
    "    print('F1 Score XGB:', f1_score)\n",
    "    print('ROC AUC XGB:', roc_auc)\n",
    "    print('\\n')\n",
    "\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test, np.round(preds_catboost[:,1]))\n",
    "    f1_score = sklearn.metrics.f1_score(y_test, np.round(preds_catboost[:,1]), average='macro')\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(y_test, preds_catboost[:,1], average='macro', multi_class='ovo')\n",
    "\n",
    "    print('Accuracy CatBoost:', accuracy)\n",
    "    print('F1 Score CatBoost:', f1_score)\n",
    "    print('ROC AUC CatBoost:', roc_auc)\n",
    "    print('\\n')\n",
    "elif args['objective'] == 'classification':\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test, np.argmax(preds_grande, axis=1))\n",
    "    f1_score = sklearn.metrics.f1_score(y_test, np.argmax(preds_grande, axis=1), average='macro')\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(y_test, preds_grande, average='macro', multi_class='ovo', labels=[i for i in range(preds_grande.shape[1])])\n",
    "\n",
    "    print('Accuracy GRANDE:', accuracy)\n",
    "    print('F1 Score GRANDE:', f1_score)\n",
    "    print('ROC AUC GRANDE:', roc_auc)\n",
    "    print('\\n')\n",
    "\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test, np.argmax(preds_xgb, axis=1))\n",
    "    f1_score = sklearn.metrics.f1_score(y_test, np.argmax(preds_xgb, axis=1), average='macro')\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(y_test, preds_xgb, average='macro', multi_class='ovo', labels=[i for i in range(preds_grande.shape[1])])\n",
    "\n",
    "    print('Accuracy XGB:', accuracy)\n",
    "    print('F1 Score XGB:', f1_score)\n",
    "    print('ROC AUC XGB:', roc_auc)\n",
    "    print('\\n')\n",
    "\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test, np.argmax(preds_catboost, axis=1))\n",
    "    f1_score = sklearn.metrics.f1_score(y_test, np.argmax(preds_catboost, axis=1), average='macro')\n",
    "    roc_auc = sklearn.metrics.roc_auc_score(y_test, preds_catboost, average='macro', multi_class='ovo', labels=[i for i in range(preds_grande.shape[1])])\n",
    "\n",
    "    print('Accuracy CatBoost:', accuracy)\n",
    "    print('F1 Score CatBoost:', f1_score)\n",
    "    print('ROC AUC CatBoost:', roc_auc)\n",
    "    print('\\n')\n",
    "else:\n",
    "    mean_absolute_error = sklearn.metrics.mean_absolute_error(y_test, np.round(preds_grande))\n",
    "    r2_score = sklearn.metrics.r2_score(y_test, np.round(preds_grande))\n",
    "\n",
    "    print('MAE GRANDE:', mean_absolute_error)\n",
    "    print('R2 Score GRANDE:', r2_score)\n",
    "    print('\\n')\n",
    "\n",
    "    mean_absolute_error = sklearn.metrics.mean_absolute_error(y_test, np.round(preds_xgb))\n",
    "    r2_score = sklearn.metrics.r2_score(y_test, np.round(preds_xgb))\n",
    "\n",
    "    print('MAE XGB:', mean_absolute_error)\n",
    "    print('R2 Score XGB:', r2_score)\n",
    "    print('\\n')\n",
    "\n",
    "    mean_absolute_error = sklearn.metrics.mean_absolute_error(y_test, np.round(preds_catboost))\n",
    "    r2_score = sklearn.metrics.r2_score(y_test, np.round(preds_catboost))\n",
    "\n",
    "    print('MAE CatBoost:', mean_absolute_error)\n",
    "    print('R2 Score CatBoost:', r2_score)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f5c50b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
